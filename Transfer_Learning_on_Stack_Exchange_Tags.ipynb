{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Practical-Data-Science-2016,-Assignment-3\">Practical Data Science 2016, Assignment 3<a class=\"anchor-link\" href=\"#Practical-Data-Science-2016,-Assignment-3\">&#182;</a></h1><p>In this assignment,we participate in a <a href=\"https://www.kaggle.com/\">Kaggle</a> competition and specifically  <a href=\"https://www.kaggle.com/c/transfer-learning-on-stack-exchange-tags\">Transfer Learning on Stack Exchange Tags</a>.</p>\n",
    "<hr>\n",
    "\n",
    "<blockquote><p>Dimitrios Karamanis <br />\n",
    "Department of Informatics <br />\n",
    "Athens University of Economics and Business <br />\n",
    "dkaramanis@aueb.gr</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Question\">Question<a class=\"anchor-link\" href=\"#Question\">&#182;</a></h2><p>Provide a solution to the competition, in the best way you can. Some explanations on what the competition is about:</p>\n",
    "<ul>\n",
    "<li><p>You are given a set of Stack Exchange data dumps, in six different domains:</p>\n",
    "<ul>\n",
    "<li>biology</li>\n",
    "<li>cooking</li>\n",
    "<li>cryptography</li>\n",
    "<li>DIY</li>\n",
    "<li>robotics</li>\n",
    "<li>travel. </li>\n",
    "</ul>\n",
    "<p>Each data dump contains question titles, content, and tags.</p>\n",
    "</li>\n",
    "<li><p>Your goal is to find a way to predict <em>tags</em>. But your way must be subject-neutral.</p>\n",
    "</li>\n",
    "<li><p>So, to test how well your approach works, you will use as your test data a dump from an entirely different domain: physics. You should find a method, based on the dumps of the six domains, that you can use to find tags in physics.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Question-1\">Reading the data<a class=\"anchor-link\" href=\"#Question-1\">&#182;</a></h2>\n",
    "<p>We downloal the data from the competition's site and read them after importing necessary libraries</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import stop_words\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from sklearn import svm\n",
    "from gensim import corpora, models, similarities\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from nltk.probability import FreqDist\n",
    "import distance\n",
    "import RAKE\n",
    "import operator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read the data\n",
    "df1 = pd.read_csv('biology.csv')\n",
    "df2 = pd.read_csv('cooking.csv')\n",
    "df3 = pd.read_csv('crypto.csv')\n",
    "df4 = pd.read_csv('diy.csv')\n",
    "df5 = pd.read_csv('robotics.csv')\n",
    "df6 = pd.read_csv('travel.csv')\n",
    "df7 = pd.read_csv('test.csv')\n",
    "\n",
    "#set category columns\n",
    "df1['category']='biology'\n",
    "df2['category']='cooking'\n",
    "df3['category']='crypto'\n",
    "df4['category']='diy'\n",
    "df5['category']='robotics'\n",
    "df6['category']='travel'\n",
    "df7['category']='physics'\n",
    "df7['tags']=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#concatenate the data and put category number\n",
    "all_df = pd.concat([ df[['title','content','tags','category']] for df in [df1, df2, df3, df4, df5,df6] ])\n",
    "all_df['category_num'] = all_df.category.map({'biology':0, 'cooking':1,'crypto':2, 'diy':3,'robotics':4, 'travel':5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Let's see how the data look:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "      <th>category</th>\n",
       "      <th>category_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the criticality of the ribosome bindin...</td>\n",
       "      <td>&lt;p&gt;In prokaryotic translation, how critical fo...</td>\n",
       "      <td>ribosome binding-sites translation synthetic-b...</td>\n",
       "      <td>biology</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How is RNAse contamination in RNA based experi...</td>\n",
       "      <td>&lt;p&gt;Does anyone have any suggestions to prevent...</td>\n",
       "      <td>rna biochemistry</td>\n",
       "      <td>biology</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Are lymphocyte sizes clustered in two groups?</td>\n",
       "      <td>&lt;p&gt;Tortora writes in &lt;em&gt;Principles of Anatomy...</td>\n",
       "      <td>immunology cell-biology hematology</td>\n",
       "      <td>biology</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How long does antibiotic-dosed LB maintain goo...</td>\n",
       "      <td>&lt;p&gt;Various people in our lab will prepare a li...</td>\n",
       "      <td>cell-culture</td>\n",
       "      <td>biology</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is exon order always preserved in splicing?</td>\n",
       "      <td>&lt;p&gt;Are there any cases in which the splicing m...</td>\n",
       "      <td>splicing mrna spliceosome introns exons</td>\n",
       "      <td>biology</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  What is the criticality of the ribosome bindin...   \n",
       "1  How is RNAse contamination in RNA based experi...   \n",
       "2      Are lymphocyte sizes clustered in two groups?   \n",
       "3  How long does antibiotic-dosed LB maintain goo...   \n",
       "4        Is exon order always preserved in splicing?   \n",
       "\n",
       "                                             content  \\\n",
       "0  <p>In prokaryotic translation, how critical fo...   \n",
       "1  <p>Does anyone have any suggestions to prevent...   \n",
       "2  <p>Tortora writes in <em>Principles of Anatomy...   \n",
       "3  <p>Various people in our lab will prepare a li...   \n",
       "4  <p>Are there any cases in which the splicing m...   \n",
       "\n",
       "                                                tags category  category_num  \n",
       "0  ribosome binding-sites translation synthetic-b...  biology             0  \n",
       "1                                   rna biochemistry  biology             0  \n",
       "2                 immunology cell-biology hematology  biology             0  \n",
       "3                                       cell-culture  biology             0  \n",
       "4            splicing mrna spliceosome introns exons  biology             0  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>and the data for which we want to predict tags </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is spin as it relates to subatomic partic...</td>\n",
       "      <td>&lt;p&gt;I often hear about subatomic particles havi...</td>\n",
       "      <td>physics</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>What is your simplest explanation of the strin...</td>\n",
       "      <td>&lt;p&gt;How would you explain string theory to non ...</td>\n",
       "      <td>physics</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Lie theory, Representations and particle physics</td>\n",
       "      <td>&lt;p&gt;This is a question that has been posted at ...</td>\n",
       "      <td>physics</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Will Determinism be ever possible?</td>\n",
       "      <td>&lt;p&gt;What are the main problems that we need to ...</td>\n",
       "      <td>physics</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>Hamilton's Principle</td>\n",
       "      <td>&lt;p&gt;Hamilton's principle states that a dynamic ...</td>\n",
       "      <td>physics</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  What is spin as it relates to subatomic partic...   \n",
       "1   2  What is your simplest explanation of the strin...   \n",
       "2   3   Lie theory, Representations and particle physics   \n",
       "3   7                 Will Determinism be ever possible?   \n",
       "4   9                               Hamilton's Principle   \n",
       "\n",
       "                                             content category tags  \n",
       "0  <p>I often hear about subatomic particles havi...  physics       \n",
       "1  <p>How would you explain string theory to non ...  physics       \n",
       "2  <p>This is a question that has been posted at ...  physics       \n",
       "3  <p>What are the main problems that we need to ...  physics       \n",
       "4  <p>Hamilton's principle states that a dynamic ...  physics       "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now we will set stopwords that were imported from libraries and add additional one's from a freely available stopword list generated by Chris Buckley and Gerard Salton at Cornell University plus several words that we added after several tries  <a href=\"http://www.lextek.com/manuals/onix/stopwords2.html \">http://www.lextek.com/manuals/onix/stopwords2.html </a> </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "additional_stopwords = set([\"nofollow\",\"sin\", \"pi\",\"dt\" ,\"ray\",\"red\",\"20\",\"black\",\"vec\",\"difference\",\"wiki\", \"rest\",\"charged\", \"frac\",\"gt\",\"nu\",\"psi\",\"work\",\"abs\",\"png\",\"omega\",\"change\",\"vec\",\"day\",\"set\",\"high\",\"stackexchange\" , \"hat\",\"rod\",\"int\",\"mu\", \"read\",\"time\", \"image\", \"people\", \"case\",\"line\", \"years\",\"problem\", \"description\", \"imgur\", \"code\",\"key\", \"img\", \"amp\",\"emage\", \"problem\", \"good\", \"bit\", \"questions\",\"hot\", \"room\",\"message\", \"random\",\"run\", \"hash\", \"understand\",\"add\", \"number\",  \"blockquote\",\"stack\",\"question\",\"run\", \"enter\",\"light\",\"long\",\"alt\",\"days\",\"small\", \"has\",\"long\",'www',\"end\", 'http','href','https', 'com', 'org', 'x', 'li','0', '1', '2', '3','4', '5', \"a\",\"br\",\"i\",\"ol\", \"tr\",\"u\",\"td\",\"li\",\"il\",\"em\",\"rel\", \n",
    "'6', \"lt\",\"ve\", \"src\", \"strong\",\"ul\",\"10\", \"en\", \"pre\",'7','8', '9','t','s', 'm', 'p', 'n',\"a\",\"a's\",\"able\",\"about\",\"above\",\"according\",\"accordingly\",\"across\",\"actually\",\"after\",\"afterwards\",\n",
    "\"again\",\"against\",\"ain't\",\"all\",\"allow\",\"allows\",\"almost\",\"alone\",\"along\",\"already\",\"also\",\"although\",\n",
    "\"always\",\"am\",\"among\",\"amongst\",\"an\",\"and\",\"another\",\"any\",\"anybody\",\"anyhow\",\"anyone\",\"anything\",\"anyway\",\n",
    "\"anyways\",\"anywhere\",\"apart\",\"appear\",\"appreciate\",\"appropriate\",\"are\",\"aren't\",\"around\",\"as\",\"aside\",\"ask\",\n",
    "\"asking\",\"associated\",\"at\",\"available\",\"away\",\"awfully\",\"b\",\"be\",\"became\",\"because\",\"become\",\"becomes\",\n",
    "\"becoming\",\"been\",\"before\",\"beforehand\",\"behind\",\"being\",\"believe\",\"below\",\"beside\",\"besides\",\"best\",\n",
    "\"better\",\"between\",\"beyond\",\"both\",\"brief\",\"but\",\"by\",\"c\",\"c'mon\",\"c's\",\"came\",\"can\",\"can't\",\"cannot\",\n",
    "\"cant\",\"cause\",\"causes\",\"certain\",\"certainly\",\"changes\",\"clearly\",\"co\",\"com\",\"come\",\"comes\",\"concerning\",\n",
    "\"consequently\",\"consider\",\"considering\",\"contain\",\"containing\",\"contains\",\"corresponding\",\"could\",\"couldn't\",\n",
    "\"course\",\"currently\",\"d\",\"definitely\",\"described\",\"despite\",\"did\",\"didn't\",\"different\",\"do\",\"does\",\"doesn't\",\n",
    "\"doing\",\"don't\",\"done\",\"down\",\"downwards\",\"during\",\"e\",\"each\",\"edu\",\"eg\",\"eight\",\"either\",\"else\",\"elsewhere\",\n",
    "\"enough\",\"entirely\",\"especially\",\"et\",\"etc\",\"even\",\"ever\",\"every\",\"everybody\",\"everyone\",\"everything\",\n",
    "\"everywhere\",\"ex\",\"exactly\",\"example\",\"except\",\"f\",\"far\",\"few\",\"fifth\",\"first\",\"five\",\"followed\",\"following\",\n",
    "\"follows\",\"for\",\"former\",\"formerly\",\"forth\",\"four\",\"from\",\"further\",\"furthermore\",\"g\",\"get\",\"gets\",\"getting\",\n",
    "\"given\",\"gives\",\"go\",\"goes\",\"going\",\"gone\",\"got\",\"gotten\",\"greetings\",\"h\",\"had\",\"hadn't\",\"happens\",\"hardly\",\n",
    "\"has\",\"hasn't\",\"have\",\"haven't\",\"having\",\"he\",\"he's\",\"hello\",\"help\",\"hence\",\"her\",\"here\",\"here's\",\"hereafter\",\n",
    "\"hereby\",\"herein\",\"hereupon\",\"hers\",\"herself\",\"hi\",\"him\",\"himself\",\"his\",\"hither\",\"hopefully\",\"how\",\"howbeit\",\n",
    "\"however\",\"i\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"ie\",\"if\",\"ignored\",\"immediate\",\"in\",\"inasmuch\",\"inc\",\"indeed\",\"indicate\",\n",
    "\"indicated\",\"indicates\",\"inner\",\"insofar\",\"instead\",\"into\",\"inward\",\"is\",\"isn't\",\"it\",\"it'd\",\"it'll\",\"it's\",\n",
    "\"its\",\"itself\",\"j\",\"just\",\"k\",\"keep\",\"keeps\",\"kept\",\"know\",\"knows\",\"known\",\"l\",\"last\",\"lately\",\"later\",\"latter\"\n",
    ",\"latterly\",\"least\",\"less\",\"lest\",\"let\",\"let's\",\"like\",\"liked\",\"likely\",\"little\",\"look\",\"looking\",\"looks\",\"ltd\",\n",
    "\"m\",\"mainly\",\"many\",\"may\",\"maybe\",\"me\",\"mean\",\"meanwhile\",\"merely\",\"might\",\"more\",\"moreover\",\"most\",\"mostly\",\n",
    "\"much\",\"must\",\"my\",\"myself\",\"n\",\"name\",\"namely\",\"nd\",\"near\",\"nearly\",\"necessary\",\"need\",\"needs\",\"neither\",\n",
    "\"never\",\"nevertheless\",\"new\",\"next\",\"nine\",\"no\",\"nobody\",\"non\",\"none\",\"noone\",\"nor\",\"normally\",\"not\",\n",
    "\"nothing\",\"novel\",\"now\",\"nowhere\",\"o\",\"obviously\",\"of\",\"off\",\"often\",\"oh\",\"ok\",\"okay\",\"old\",\"on\",\"once\",\n",
    "\"one\",\"ones\",\"only\",\"onto\",\"or\",\"other\",\"others\",\"otherwise\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"outside\",\n",
    "\"over\",\"overall\",\"own\",\"p\",\"particular\",\"particularly\",\"per\",\"perhaps\",\"placed\",\"please\",\"plus\",\"possible\",\n",
    "\"presumably\",\"probably\",\"provides\",\"q\",\"que\",\"quite\",\"qv\",\"r\",\"rather\",\"rd\",\"re\",\"really\",\"reasonably\",\n",
    "\"regarding\",\"regardless\",\"regards\",\"relatively\",\"respectively\",\"right\",\"s\",\"said\",\"same\",\"saw\",\"say\",\n",
    "\"saying\",\"says\",\"second\",\"secondly\",\"see\",\"seeing\",\"seem\",\"seemed\",\"seeming\",\"seems\",\"seen\",\"self\",\"selves\",\n",
    "\"sensible\",\"sent\",\"serious\",\"seriously\",\"seven\",\"several\",\"shall\",\"she\",\"should\",\"shouldn't\",\"since\",\"six\",\n",
    "\"so\",\"some\",\"somebody\",\"somehow\",\"someone\",\"something\",\"sometime\",\"sometimes\",\"somewhat\",\"somewhere\",\"soon\",\n",
    "\"sorry\",\"specified\",\"specify\",\"specifying\",\"still\",\"sub\",\"such\",\"sup\",\"sure\",\"t\",\"t's\",\"take\",\"taken\",\"tell\",\n",
    "\"tends\",\"th\",\"than\",\"thank\",\"thanks\",\"thanx\",\"that\",\"that's\",\"thats\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\n",
    "\"then\",\"thence\",\"there\",\"there's\",\"thereafter\",\"thereby\",\"therefore\",\"therein\",\"theres\",\"thereupon\",\"these\",\n",
    "\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"think\",\"third\",\"this\",\"thorough\",\"thoroughly\",\"those\",\"though\",\n",
    "\"three\",\"through\",\"throughout\",\"thru\",\"thus\",\"to\",\"together\",\"too\",\"took\",\"toward\",\"towards\",\"tried\",\"tries\",\n",
    "\"truly\",\"try\",\"trying\",\"twice\",\"two\",\"u\",\"un\",\"under\",\"unfortunately\",\"unless\",\"unlikely\",\"until\",\"unto\",\"up\",\n",
    "\"upon\",\"us\",\"use\",\"used\",\"useful\",\"uses\",\"using\",\"usually\",\"uucp\",\"v\",\"value\",\"various\",\"very\",\"via\",\"viz\",\n",
    "\"vs\",\"w\",\"want\",\"wants\",\"was\",\"wasn't\",\"way\",\"we\",\"we'd\",\"we'll\",\"we're\",\"we've\",\"welcome\",\"well\",\"went\",\n",
    "\"were\",\"weren't\",\"what\",\"what's\",\"whatever\",\"when\",\"whence\",\"whenever\",\"where\",\"where's\",\"whereafter\",\n",
    "\"whereas\",\"whereby\",\"wherein\",\"whereupon\",\"wherever\",\"whether\",\"which\",\"while\",\"whither\",\"who\",\"who's\",\n",
    "\"whoever\",\"whole\",\"whom\",\"whose\",\"why\",\"will\",\"willing\",\"wish\",\"with\",\"within\",\"without\",\"won't\",\"wonder\",\n",
    "\"would\",\"would\",\"wouldn't\",\"x\",\"y\",\"yes\",\"yet\",\"you\",\"you'd\",\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\n",
    "\"yourself\",\"yourselves\",\"z\",\"zero\"])\n",
    "stopwords = set(STOPWORDS) | additional_stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Idea No 1<a class=\"anchor-link\" ></a></h2>\n",
    "<p>Our first idea is  try to find tag words, after training the already occured set of tokens in the datasets df1 to df6. </p>\n",
    "<p> We will construct a dataframe with the whole set of token/words in title+content and set a column with value zero if that word didn't appear as tag , or value one if that word actually appeared as a tag. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> First we will put in a dataframe all tokens from title+content, from our train dataset from all topics (87000 posts), after cleaning it from stopwords and punctuation </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29743</th>\n",
       "      <td>water</td>\n",
       "      <td>20356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60457</th>\n",
       "      <td>jpg</td>\n",
       "      <td>19825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46864</th>\n",
       "      <td>visa</td>\n",
       "      <td>17096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50362</th>\n",
       "      <td>wall</td>\n",
       "      <td>11305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17101</th>\n",
       "      <td>house</td>\n",
       "      <td>11065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119890</th>\n",
       "      <td>travel</td>\n",
       "      <td>8930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26012</th>\n",
       "      <td>wire</td>\n",
       "      <td>8432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82924</th>\n",
       "      <td>switch</td>\n",
       "      <td>7925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43036</th>\n",
       "      <td>uk</td>\n",
       "      <td>7237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44876</th>\n",
       "      <td>floor</td>\n",
       "      <td>7154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92645</th>\n",
       "      <td>data</td>\n",
       "      <td>6878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126498</th>\n",
       "      <td>home</td>\n",
       "      <td>6661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150398</th>\n",
       "      <td>flight</td>\n",
       "      <td>6642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11240</th>\n",
       "      <td>air</td>\n",
       "      <td>6008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100339</th>\n",
       "      <td>encryption</td>\n",
       "      <td>5969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65806</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>5958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88913</th>\n",
       "      <td>box</td>\n",
       "      <td>5759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105549</th>\n",
       "      <td>passport</td>\n",
       "      <td>5712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58640</th>\n",
       "      <td>door</td>\n",
       "      <td>5430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37479</th>\n",
       "      <td>power</td>\n",
       "      <td>5343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Token  Frequency\n",
       "29743        water      20356\n",
       "60457          jpg      19825\n",
       "46864         visa      17096\n",
       "50362         wall      11305\n",
       "17101        house      11065\n",
       "119890      travel       8930\n",
       "26012         wire       8432\n",
       "82924       switch       7925\n",
       "43036           uk       7237\n",
       "44876        floor       7154\n",
       "92645         data       6878\n",
       "126498        home       6661\n",
       "150398      flight       6642\n",
       "11240          air       6008\n",
       "100339  encryption       5969\n",
       "65806    wikipedia       5958\n",
       "88913          box       5759\n",
       "105549    passport       5712\n",
       "58640         door       5430\n",
       "37479        power       5343"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RE_PUNCTUATION = '|'.join([re.escape(x) for x in string.punctuation])\n",
    "train=all_df[['title','content','tags']]\n",
    "train['title'] = train['title'].str.lower().str.replace(RE_PUNCTUATION, ' ') #remove puntuation from title\n",
    "train['content'] = train['content'].str.lower().str.replace(RE_PUNCTUATION, ' ')  #remove puntuation from content\n",
    "train['title_content']=train['title']+train['content'] #merge the two columns of interest\n",
    "train['title_content_tokens'] = train['title_content'].str.split() #split to strings\n",
    "#remove stopwords\n",
    "train['title_content_tokens'] = train['title_content_tokens'].apply(lambda tokens: [token for token in tokens if token not in stopwords])\n",
    "# put tokens to a Dataframe after counting their frequency\n",
    "tokens=train['title_content_tokens'].tolist() \n",
    "tokens = np.asarray(tokens)\n",
    "tokens=[j for i in tokens for j in i]\n",
    "fdist = FreqDist(tokens)\n",
    "train_title_content = pd.DataFrame.from_dict(fdist, orient='index').reset_index()\n",
    "#rename columns\n",
    "train_title_content.rename(columns = {'index':'Token', 0:'Frequency'}, inplace=True)\n",
    "#sorting\n",
    "train_title_content=train_title_content[['Token','Frequency']].sort_values(by='Frequency',ascending=False)\n",
    "train_title_content.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Now let's put unique tags from the 87000 posts in a dataframe </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4268, 2)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tags_tokens'] = train['tags'].str.split()\n",
    "tokens_tags=train['tags_tokens'].tolist()\n",
    "tokens_tags = np.asarray(tokens_tags)\n",
    "tokens_tags=[j for i in tokens_tags for j in i]\n",
    "train_tags = FreqDist(tokens_tags)\n",
    "train_tags = pd.DataFrame.from_dict(train_tags, orient='index').reset_index()\n",
    "train_tags.rename(columns = {'index':'Token', 0:'Frequency_Tag'}, inplace=True)\n",
    "train_tags=train_tags[['Token','Frequency_Tag']].sort_values(by='Frequency_Tag',ascending=False)\n",
    "train_tags.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> As we see there are 4268 different tags</p> <p> Now let's see the most frequent one's </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Frequency_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>electrical</td>\n",
       "      <td>4490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>visas</td>\n",
       "      <td>3829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>air-travel</td>\n",
       "      <td>2273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>plumbing</td>\n",
       "      <td>2223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>usa</td>\n",
       "      <td>2168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2628</th>\n",
       "      <td>encryption</td>\n",
       "      <td>1783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>wiring</td>\n",
       "      <td>1680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3589</th>\n",
       "      <td>schengen</td>\n",
       "      <td>1561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415</th>\n",
       "      <td>uk</td>\n",
       "      <td>1522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>human-biology</td>\n",
       "      <td>1448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>baking</td>\n",
       "      <td>1444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3701</th>\n",
       "      <td>genetics</td>\n",
       "      <td>1229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>food-safety</td>\n",
       "      <td>1211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>evolution</td>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150</th>\n",
       "      <td>hash</td>\n",
       "      <td>1141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>rsa</td>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>customs-and-immigration</td>\n",
       "      <td>1067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>transit</td>\n",
       "      <td>1016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4191</th>\n",
       "      <td>lighting</td>\n",
       "      <td>1003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>biochemistry</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Token  Frequency_Tag\n",
       "2982               electrical           4490\n",
       "1892                    visas           3829\n",
       "1832               air-travel           2273\n",
       "2056                 plumbing           2223\n",
       "2230                      usa           2168\n",
       "2628               encryption           1783\n",
       "2380                   wiring           1680\n",
       "3589                 schengen           1561\n",
       "3415                       uk           1522\n",
       "3096            human-biology           1448\n",
       "1824                   baking           1444\n",
       "3701                 genetics           1229\n",
       "1369              food-safety           1211\n",
       "2475                evolution           1159\n",
       "4150                     hash           1141\n",
       "3632                      rsa           1095\n",
       "2564  customs-and-immigration           1067\n",
       "1489                  transit           1016\n",
       "4191                 lighting           1003\n",
       "513              biochemistry            984"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tags.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Now we will merge the two dataframe on column token </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_tokens = pd.merge(train_title_content, train_tags,how='left', on='Token')\n",
    "train_tokens=train_tokens.fillna(0) #fill NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frequency_Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>water</td>\n",
       "      <td>20356</td>\n",
       "      <td>861.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jpg</td>\n",
       "      <td>19825</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>visa</td>\n",
       "      <td>17096</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wall</td>\n",
       "      <td>11305</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>house</td>\n",
       "      <td>11065</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>travel</td>\n",
       "      <td>8930</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wire</td>\n",
       "      <td>8432</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>switch</td>\n",
       "      <td>7925</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>uk</td>\n",
       "      <td>7237</td>\n",
       "      <td>1522.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>floor</td>\n",
       "      <td>7154</td>\n",
       "      <td>371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data</td>\n",
       "      <td>6878</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>home</td>\n",
       "      <td>6661</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>flight</td>\n",
       "      <td>6642</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>air</td>\n",
       "      <td>6008</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>encryption</td>\n",
       "      <td>5969</td>\n",
       "      <td>1783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>wikipedia</td>\n",
       "      <td>5958</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>box</td>\n",
       "      <td>5759</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>passport</td>\n",
       "      <td>5712</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>door</td>\n",
       "      <td>5430</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>power</td>\n",
       "      <td>5343</td>\n",
       "      <td>239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ceiling</td>\n",
       "      <td>5300</td>\n",
       "      <td>390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>airport</td>\n",
       "      <td>5208</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>public</td>\n",
       "      <td>5147</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cooking</td>\n",
       "      <td>5098</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ground</td>\n",
       "      <td>5089</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>recipe</td>\n",
       "      <td>4949</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>point</td>\n",
       "      <td>4939</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>type</td>\n",
       "      <td>4809</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>size</td>\n",
       "      <td>4797</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>white</td>\n",
       "      <td>4784</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>wondering</td>\n",
       "      <td>4723</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>place</td>\n",
       "      <td>4708</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>function</td>\n",
       "      <td>4623</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>information</td>\n",
       "      <td>4621</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>kind</td>\n",
       "      <td>4585</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>fan</td>\n",
       "      <td>4560</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>trip</td>\n",
       "      <td>4506</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>idea</td>\n",
       "      <td>4446</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>area</td>\n",
       "      <td>4386</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>inside</td>\n",
       "      <td>4362</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>heat</td>\n",
       "      <td>4344</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>wires</td>\n",
       "      <td>4325</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>left</td>\n",
       "      <td>4313</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>pipe</td>\n",
       "      <td>4309</td>\n",
       "      <td>282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>single</td>\n",
       "      <td>4292</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>making</td>\n",
       "      <td>4282</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>concrete</td>\n",
       "      <td>4207</td>\n",
       "      <td>714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>lot</td>\n",
       "      <td>4205</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>based</td>\n",
       "      <td>4195</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>food</td>\n",
       "      <td>4173</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Token  Frequency  Frequency_Tag\n",
       "0         water      20356          861.0\n",
       "1           jpg      19825            0.0\n",
       "2          visa      17096            0.0\n",
       "3          wall      11305            0.0\n",
       "4         house      11065            0.0\n",
       "5        travel       8930            0.0\n",
       "6          wire       8432          102.0\n",
       "7        switch       7925          500.0\n",
       "8            uk       7237         1522.0\n",
       "9         floor       7154          371.0\n",
       "10         data       6878           41.0\n",
       "11         home       6661            0.0\n",
       "12       flight       6642           13.0\n",
       "13          air       6008            0.0\n",
       "14   encryption       5969         1783.0\n",
       "15    wikipedia       5958            0.0\n",
       "16          box       5759            0.0\n",
       "17     passport       5712            0.0\n",
       "18         door       5430            0.0\n",
       "19        power       5343          239.0\n",
       "20      ceiling       5300          390.0\n",
       "21      airport       5208            0.0\n",
       "22       public       5147            0.0\n",
       "23      cooking       5098            0.0\n",
       "24       ground       5089           19.0\n",
       "25       recipe       4949            0.0\n",
       "26        point       4939            0.0\n",
       "27         type       4809            0.0\n",
       "28         size       4797            0.0\n",
       "29        white       4784            0.0\n",
       "30    wondering       4723            0.0\n",
       "31        place       4708            0.0\n",
       "32     function       4623            0.0\n",
       "33  information       4621            7.0\n",
       "34         kind       4585            0.0\n",
       "35          fan       4560           48.0\n",
       "36         trip       4506            0.0\n",
       "37         idea       4446            6.0\n",
       "38         area       4386            0.0\n",
       "39       inside       4362            0.0\n",
       "40         heat       4344          106.0\n",
       "41        wires       4325            0.0\n",
       "42         left       4313            0.0\n",
       "43         pipe       4309          282.0\n",
       "44       single       4292            0.0\n",
       "45       making       4282            0.0\n",
       "46     concrete       4207          714.0\n",
       "47          lot       4205            0.0\n",
       "48        based       4195            0.0\n",
       "49         food       4173          156.0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> We have an indication that  many frequent words are appearing actually as tags </p><p> Let's compute the Relative Frequencies and train our model </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_tokens['Relative_Freq']=train_tokens['Frequency']/train_tokens['Frequency'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frequency_Tag</th>\n",
       "      <th>Relative_Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>water</td>\n",
       "      <td>20356</td>\n",
       "      <td>861.0</td>\n",
       "      <td>0.004917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jpg</td>\n",
       "      <td>19825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>visa</td>\n",
       "      <td>17096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wall</td>\n",
       "      <td>11305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>house</td>\n",
       "      <td>11065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>travel</td>\n",
       "      <td>8930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wire</td>\n",
       "      <td>8432</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.002037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>switch</td>\n",
       "      <td>7925</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.001914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>uk</td>\n",
       "      <td>7237</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>0.001748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>floor</td>\n",
       "      <td>7154</td>\n",
       "      <td>371.0</td>\n",
       "      <td>0.001728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Token  Frequency  Frequency_Tag  Relative_Freq\n",
       "0   water      20356          861.0       0.004917\n",
       "1     jpg      19825            0.0       0.004789\n",
       "2    visa      17096            0.0       0.004130\n",
       "3    wall      11305            0.0       0.002731\n",
       "4   house      11065            0.0       0.002673\n",
       "5  travel       8930            0.0       0.002157\n",
       "6    wire       8432          102.0       0.002037\n",
       "7  switch       7925          500.0       0.001914\n",
       "8      uk       7237         1522.0       0.001748\n",
       "9   floor       7154          371.0       0.001728"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Now we will put a dummy variable for each token, if it appeared actually as a tag </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tokens['tag']=''\n",
    "train_tokens['tag'] = (train_tokens['Frequency_Tag'] > 0)\n",
    "train_tokens['tag']=train_tokens['tag']*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Frequency_Tag</th>\n",
       "      <th>Relative_Freq</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>water</td>\n",
       "      <td>20356</td>\n",
       "      <td>861.0</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jpg</td>\n",
       "      <td>19825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004789</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>visa</td>\n",
       "      <td>17096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wall</td>\n",
       "      <td>11305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>house</td>\n",
       "      <td>11065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002673</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>travel</td>\n",
       "      <td>8930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wire</td>\n",
       "      <td>8432</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>switch</td>\n",
       "      <td>7925</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>uk</td>\n",
       "      <td>7237</td>\n",
       "      <td>1522.0</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>floor</td>\n",
       "      <td>7154</td>\n",
       "      <td>371.0</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Token  Frequency  Frequency_Tag  Relative_Freq  tag\n",
       "0   water      20356          861.0       0.004917    1\n",
       "1     jpg      19825            0.0       0.004789    0\n",
       "2    visa      17096            0.0       0.004130    0\n",
       "3    wall      11305            0.0       0.002731    0\n",
       "4   house      11065            0.0       0.002673    0\n",
       "5  travel       8930            0.0       0.002157    0\n",
       "6    wire       8432          102.0       0.002037    1\n",
       "7  switch       7925          500.0       0.001914    1\n",
       "8      uk       7237         1522.0       0.001748    1\n",
       "9   floor       7154          371.0       0.001728    1"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Now we will train a model using <a href=\"https://en.wikipedia.org/wiki/Logistic_regression\">Logistic Regression </a> with the token's Relative Frequencies as independent variable and the dummy 'tag' variable as dependent categorical variable. This way we will try to catch in the physics category, if the Relative Frequency of a token in the title+content, can predict if that word will be actually a tag. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "\n",
    "# train the model \n",
    "X=np.transpose(np.matrix(train_tokens['Relative_Freq']))\n",
    "y=np.transpose(np.matrix(train_tokens['tag']))\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98237769594950031"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the accuracy on the training set\n",
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Now we will  put the physics-tokens in a dataframe, we will compute their Relative Frequency and try to predict if they will be actually a tag throught their relative frequency in the title+content. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "physics=df7\n",
    "physics['title'] = physics['title'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "physics['content'] = physics['content'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "physics['title_content']=physics['title']+physics['content']\n",
    "physics['title_content_tokens'] = physics['title_content'].str.split()\n",
    "physics['title_content_tokens'] = physics['title_content_tokens'].apply(lambda tokens: [token for token in tokens if token not in stopwords])\n",
    "tokens_new=physics['title_content_tokens'].tolist()\n",
    "tokens_new = np.asarray(tokens_new)\n",
    "tokens_new=[j for i in tokens_new for j in i]\n",
    "fdist_new = FreqDist(tokens_new)\n",
    "physics_tokens = pd.DataFrame.from_dict(fdist_new, orient='index').reset_index()\n",
    "physics_tokens.rename(columns = {'index':'Token', 0:'Frequency'}, inplace=True)\n",
    "physics_tokens['Relative_Freq']=physics_tokens['Frequency']/physics_tokens['Frequency'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Relative_Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53127</th>\n",
       "      <td>energy</td>\n",
       "      <td>38682</td>\n",
       "      <td>0.008551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75989</th>\n",
       "      <td>field</td>\n",
       "      <td>28503</td>\n",
       "      <td>0.006301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52305</th>\n",
       "      <td>partial</td>\n",
       "      <td>24065</td>\n",
       "      <td>0.005320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26094</th>\n",
       "      <td>equation</td>\n",
       "      <td>22814</td>\n",
       "      <td>0.005043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78656</th>\n",
       "      <td>force</td>\n",
       "      <td>22507</td>\n",
       "      <td>0.004975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81522</th>\n",
       "      <td>mass</td>\n",
       "      <td>21370</td>\n",
       "      <td>0.004724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24578</th>\n",
       "      <td>left</td>\n",
       "      <td>20097</td>\n",
       "      <td>0.004442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49189</th>\n",
       "      <td>phi</td>\n",
       "      <td>18552</td>\n",
       "      <td>0.004101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100041</th>\n",
       "      <td>space</td>\n",
       "      <td>18538</td>\n",
       "      <td>0.004098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87928</th>\n",
       "      <td>physics</td>\n",
       "      <td>18377</td>\n",
       "      <td>0.004062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Token  Frequency  Relative_Freq\n",
       "53127     energy      38682       0.008551\n",
       "75989      field      28503       0.006301\n",
       "52305    partial      24065       0.005320\n",
       "26094   equation      22814       0.005043\n",
       "78656      force      22507       0.004975\n",
       "81522       mass      21370       0.004724\n",
       "24578       left      20097       0.004442\n",
       "49189        phi      18552       0.004101\n",
       "100041     space      18538       0.004098\n",
       "87928    physics      18377       0.004062"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physics_tokens=physics_tokens[['Token','Frequency','Relative_Freq']].sort_values(by='Relative_Freq',ascending=False)\n",
    "physics_tokens.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Now we will predict if a token will be a tag, through its relative frequency</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "physics_tokens_test=np.transpose(np.matrix(physics_tokens['Relative_Freq']))\n",
    "predicted =model.predict(physics_tokens_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check if token took value 1 as a tag\n",
    "sum(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> So our idea didn't work, no tags where predicted </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Idea No 2<a class=\"anchor-link\" ></a></h2>\n",
    "<p>We will use a Python module implementation of the Rapid Automatic Keyword Extraction (RAKE) algorithm as described in: Rose, S., Engel, D., Cramer, N., & Cowley, W. (2010). Automatic Keyword Extraction from Individual Documents </p>\n",
    "<p> That means will not take into account the allready existed topics. </p>\n",
    "<p> RAKE module needs a list of stopwords to be given as a txt file.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import RAKE\n",
    "import operator\n",
    "\n",
    "Rake = RAKE.Rake('SmartStoplist.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>actual spinning motionproperty called spin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>explain string theorystring theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>lie theory representationslie groups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>uncertainty principlemain problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>action integraldynamic system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>term soundsound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>support string theorydisprove theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>sky change colorsunrise set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19</td>\n",
       "      <td>particle collisions calculatedhigher energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>monte carlo methodmonte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24</td>\n",
       "      <td>bike moves forward relativesteering wheel left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26</td>\n",
       "      <td>electromagnetic fieldrail gun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27</td>\n",
       "      <td>checked decreases dramaticallyclassical mechan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>29</td>\n",
       "      <td>frac hoursfrac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31</td>\n",
       "      <td>en wikipedia org wiki special relativity rel n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32</td>\n",
       "      <td>household experimentswhirl vortex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>35</td>\n",
       "      <td>opposite polespoles facing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>37</td>\n",
       "      <td>papers booksmathematical theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>41</td>\n",
       "      <td>word proceeding fieldconformal field theories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49</td>\n",
       "      <td>capacitive screen sensingcapacitive touchscreen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               tags\n",
       "0    1         actual spinning motionproperty called spin\n",
       "1    2                 explain string theorystring theory\n",
       "2    3               lie theory representationslie groups\n",
       "3    7                 uncertainty principlemain problems\n",
       "4    9                      action integraldynamic system\n",
       "5   13                                    term soundsound\n",
       "6   15               support string theorydisprove theory\n",
       "7   17                        sky change colorsunrise set\n",
       "8   19        particle collisions calculatedhigher energy\n",
       "9   21                            monte carlo methodmonte\n",
       "10  24     bike moves forward relativesteering wheel left\n",
       "11  26                      electromagnetic fieldrail gun\n",
       "12  27  checked decreases dramaticallyclassical mechan...\n",
       "13  29                                     frac hoursfrac\n",
       "14  31  en wikipedia org wiki special relativity rel n...\n",
       "15  32                  household experimentswhirl vortex\n",
       "16  35                         opposite polespoles facing\n",
       "17  37                    papers booksmathematical theory\n",
       "18  41      word proceeding fieldconformal field theories\n",
       "19  49    capacitive screen sensingcapacitive touchscreen"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rake.run(str(physics['title_content'][0]))\n",
    "\n",
    "#because of memory errors we will predict tags only for 20 first posts\n",
    "#for i in range(0,len(physics['title_content']):\n",
    "for i in range(0,20):\n",
    "    a= Rake.run(str(physics['title_content'][i]))\n",
    "    a=dict(a)\n",
    "    myList = sorted(a, key=a.get, reverse=True)\n",
    "    if len(myList)>=2:\n",
    "        physics['tags'][i]=myList[0]+myList[1]\n",
    "    else:\n",
    "        physics['tags'][i]=myList[0]\n",
    "    physics['tags'][i]=re.sub(r'\\w*\\d\\w*', '', df7['tags'][i]).strip()\n",
    "    physics['tags'][i]=physics['tags'][i].split()\n",
    "    physics['tags'][i]= \" \".join(sorted(set(physics['tags'][i]), key=physics['tags'][i].index))\n",
    "\n",
    "#tocsv=physics[['id','tags']]\n",
    "#tocsv.to_csv('example.csv', sep=',', encoding='utf-8', index=False)\n",
    "physics[['id','tags']].head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Idea No 3<a class=\"anchor-link\" ></a></h2>\n",
    "<p><u>First</u>: We will explore the frequencies of the actual token-tags and we will find an average number of most usual token-tags in the  known topics.</p>\n",
    "<p><u>Second</u>: As we find how many are actually the most important/frequent tags, we will use the LDA method with the logic that in every topic, there must be subtopics, so will find top words for every subtopic and therefore for every topic.</p>\n",
    "<p><u>Third</u>: We will apply this idea to a topic as robotics to check if the predicted important words from LDA method, are actually tags, and we will calculate the differences/distance with a python's package that can be found here <a href=\"https://pypi.python.org/pypi/Distance/\">https://pypi.python.org/pypi/Distance/</a> </p>\n",
    "<p><u>Forth</u>: We will apply the method to physics to extract possible tags. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Let's explore some descriptive statistics in each topic </>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag_Name</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asexual</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quantitative</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>identification</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anecdotal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flowers</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>histology</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>untagged</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>matrix</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lymph</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>energy</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Tag_Name  Frequency\n",
       "0         asexual          3\n",
       "1    quantitative         25\n",
       "2  identification        462\n",
       "3       anecdotal          2\n",
       "4         flowers         21\n",
       "5       histology         40\n",
       "6        untagged          6\n",
       "7          matrix          4\n",
       "8           lymph          4\n",
       "9          energy         35"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXPLORE biology\n",
    "#remove punctuation and prepare tokens to constuct a dataframe \n",
    "df1['title'] = df1['title'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "df1['content'] = df1['content'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "df1['tags'] = df1['tags'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "df1['title_content']=df1['title']+df1['content']\n",
    "#create Dataframe with the allready existed tags\n",
    "df1['tags_tokens'] = df1['tags'].str.split()\n",
    "tokens_tags=df1['tags_tokens'].tolist()\n",
    "tokens_tags = np.asarray(tokens_tags)\n",
    "tokens_tags=[j for i in tokens_tags for j in i]\n",
    "number_of_tags=len(tokens_tags) #total number of tags\n",
    "Biology_tags = FreqDist(tokens_tags)\n",
    "Biology_tags = pd.DataFrame.from_dict(Biology_tags, orient='index').reset_index()\n",
    "Biology_tags.rename(columns = {'index':'Tag_Name', 0:'Frequency'}, inplace=True)\n",
    "Biology_tags.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     710.000000\n",
       "mean       61.198592\n",
       "std       214.452480\n",
       "min         1.000000\n",
       "25%         5.250000\n",
       "50%        14.000000\n",
       "75%        40.000000\n",
       "max      3686.000000\n",
       "Name: Frequency, dtype: float64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#explore Biology tags and find Frequencies\n",
    "Biology_tags=Biology_tags[['Tag_Name','Frequency']].sort_values(by='Frequency',ascending=False)\n",
    "Biology_tags['Frequency'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "710"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Biology_tags['Relative_Frequency']=Biology_tags['Frequency']/Biology_tags['Frequency'].sum()\n",
    "NUMBER_of_different_Biology_tags=len(Biology_tags)\n",
    "NUMBER_of_different_Biology_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag_Name</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Relative_Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>biology</td>\n",
       "      <td>3686</td>\n",
       "      <td>0.084831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>human</td>\n",
       "      <td>2218</td>\n",
       "      <td>0.051046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>genetics</td>\n",
       "      <td>1942</td>\n",
       "      <td>0.044694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>evolution</td>\n",
       "      <td>1302</td>\n",
       "      <td>0.029965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>molecular</td>\n",
       "      <td>1272</td>\n",
       "      <td>0.029274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>cell</td>\n",
       "      <td>1161</td>\n",
       "      <td>0.026720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>biochemistry</td>\n",
       "      <td>984</td>\n",
       "      <td>0.022646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>dna</td>\n",
       "      <td>977</td>\n",
       "      <td>0.022485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>physiology</td>\n",
       "      <td>896</td>\n",
       "      <td>0.020621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>bioinformatics</td>\n",
       "      <td>663</td>\n",
       "      <td>0.015259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>neuroscience</td>\n",
       "      <td>614</td>\n",
       "      <td>0.014131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>botany</td>\n",
       "      <td>565</td>\n",
       "      <td>0.013003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>zoology</td>\n",
       "      <td>545</td>\n",
       "      <td>0.012543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>species</td>\n",
       "      <td>486</td>\n",
       "      <td>0.011185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>identification</td>\n",
       "      <td>462</td>\n",
       "      <td>0.010633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>anatomy</td>\n",
       "      <td>456</td>\n",
       "      <td>0.010495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>proteins</td>\n",
       "      <td>443</td>\n",
       "      <td>0.010195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>microbiology</td>\n",
       "      <td>421</td>\n",
       "      <td>0.009689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>gene</td>\n",
       "      <td>379</td>\n",
       "      <td>0.008722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>entomology</td>\n",
       "      <td>378</td>\n",
       "      <td>0.008699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>homework</td>\n",
       "      <td>372</td>\n",
       "      <td>0.008561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>population</td>\n",
       "      <td>355</td>\n",
       "      <td>0.008170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>plant</td>\n",
       "      <td>337</td>\n",
       "      <td>0.007756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>immunology</td>\n",
       "      <td>331</td>\n",
       "      <td>0.007618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>metabolism</td>\n",
       "      <td>324</td>\n",
       "      <td>0.007457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>bacteriology</td>\n",
       "      <td>312</td>\n",
       "      <td>0.007181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>sequencing</td>\n",
       "      <td>277</td>\n",
       "      <td>0.006375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>ecology</td>\n",
       "      <td>275</td>\n",
       "      <td>0.006329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>rna</td>\n",
       "      <td>271</td>\n",
       "      <td>0.006237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>brain</td>\n",
       "      <td>270</td>\n",
       "      <td>0.006214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>cancer</td>\n",
       "      <td>251</td>\n",
       "      <td>0.005777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>reproduction</td>\n",
       "      <td>247</td>\n",
       "      <td>0.005685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>protein</td>\n",
       "      <td>243</td>\n",
       "      <td>0.005593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>expression</td>\n",
       "      <td>240</td>\n",
       "      <td>0.005523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>pharmacology</td>\n",
       "      <td>236</td>\n",
       "      <td>0.005431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>lab</td>\n",
       "      <td>225</td>\n",
       "      <td>0.005178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Tag_Name  Frequency  Relative_Frequency\n",
       "234         biology       3686            0.084831\n",
       "688           human       2218            0.051046\n",
       "648        genetics       1942            0.044694\n",
       "246       evolution       1302            0.029965\n",
       "586       molecular       1272            0.029274\n",
       "193            cell       1161            0.026720\n",
       "348    biochemistry        984            0.022646\n",
       "282             dna        977            0.022485\n",
       "206      physiology        896            0.020621\n",
       "229  bioinformatics        663            0.015259\n",
       "457    neuroscience        614            0.014131\n",
       "492          botany        565            0.013003\n",
       "704         zoology        545            0.012543\n",
       "334         species        486            0.011185\n",
       "2    identification        462            0.010633\n",
       "232         anatomy        456            0.010495\n",
       "351        proteins        443            0.010195\n",
       "376    microbiology        421            0.009689\n",
       "34             gene        379            0.008722\n",
       "374      entomology        378            0.008699\n",
       "695        homework        372            0.008561\n",
       "675      population        355            0.008170\n",
       "168           plant        337            0.007756\n",
       "428      immunology        331            0.007618\n",
       "35       metabolism        324            0.007457\n",
       "493    bacteriology        312            0.007181\n",
       "556      sequencing        277            0.006375\n",
       "574         ecology        275            0.006329\n",
       "214             rna        271            0.006237\n",
       "55            brain        270            0.006214\n",
       "272          cancer        251            0.005777\n",
       "145    reproduction        247            0.005685\n",
       "482         protein        243            0.005593\n",
       "666      expression        240            0.005523\n",
       "136    pharmacology        236            0.005431\n",
       "683             lab        225            0.005178"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see tags above quantile 95%\n",
    "Biology_tags.loc[Biology_tags['Relative_Frequency']>Biology_tags['Relative_Frequency'].quantile(0.95)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> We set 0.001 as a limit frequency \"for more important tags\" and we will find the percentage of total tag-words in every topic that is covered from those words</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag_Name</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Relative_Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>biology</td>\n",
       "      <td>3686</td>\n",
       "      <td>0.084831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>human</td>\n",
       "      <td>2218</td>\n",
       "      <td>0.051046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>genetics</td>\n",
       "      <td>1942</td>\n",
       "      <td>0.044694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>evolution</td>\n",
       "      <td>1302</td>\n",
       "      <td>0.029965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>molecular</td>\n",
       "      <td>1272</td>\n",
       "      <td>0.029274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>cell</td>\n",
       "      <td>1161</td>\n",
       "      <td>0.026720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>biochemistry</td>\n",
       "      <td>984</td>\n",
       "      <td>0.022646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>dna</td>\n",
       "      <td>977</td>\n",
       "      <td>0.022485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>physiology</td>\n",
       "      <td>896</td>\n",
       "      <td>0.020621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>bioinformatics</td>\n",
       "      <td>663</td>\n",
       "      <td>0.015259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>neuroscience</td>\n",
       "      <td>614</td>\n",
       "      <td>0.014131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>botany</td>\n",
       "      <td>565</td>\n",
       "      <td>0.013003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>zoology</td>\n",
       "      <td>545</td>\n",
       "      <td>0.012543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>species</td>\n",
       "      <td>486</td>\n",
       "      <td>0.011185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>identification</td>\n",
       "      <td>462</td>\n",
       "      <td>0.010633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>anatomy</td>\n",
       "      <td>456</td>\n",
       "      <td>0.010495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>proteins</td>\n",
       "      <td>443</td>\n",
       "      <td>0.010195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>microbiology</td>\n",
       "      <td>421</td>\n",
       "      <td>0.009689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>gene</td>\n",
       "      <td>379</td>\n",
       "      <td>0.008722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>entomology</td>\n",
       "      <td>378</td>\n",
       "      <td>0.008699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>homework</td>\n",
       "      <td>372</td>\n",
       "      <td>0.008561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>population</td>\n",
       "      <td>355</td>\n",
       "      <td>0.008170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>plant</td>\n",
       "      <td>337</td>\n",
       "      <td>0.007756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>immunology</td>\n",
       "      <td>331</td>\n",
       "      <td>0.007618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>metabolism</td>\n",
       "      <td>324</td>\n",
       "      <td>0.007457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>bacteriology</td>\n",
       "      <td>312</td>\n",
       "      <td>0.007181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>sequencing</td>\n",
       "      <td>277</td>\n",
       "      <td>0.006375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>ecology</td>\n",
       "      <td>275</td>\n",
       "      <td>0.006329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>rna</td>\n",
       "      <td>271</td>\n",
       "      <td>0.006237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>brain</td>\n",
       "      <td>270</td>\n",
       "      <td>0.006214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>plasmids</td>\n",
       "      <td>56</td>\n",
       "      <td>0.001289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>protocol</td>\n",
       "      <td>55</td>\n",
       "      <td>0.001266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>genome</td>\n",
       "      <td>55</td>\n",
       "      <td>0.001266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>bioenergetics</td>\n",
       "      <td>55</td>\n",
       "      <td>0.001266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>snp</td>\n",
       "      <td>55</td>\n",
       "      <td>0.001266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>translation</td>\n",
       "      <td>55</td>\n",
       "      <td>0.001266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>epigenetics</td>\n",
       "      <td>55</td>\n",
       "      <td>0.001266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>kinetics</td>\n",
       "      <td>55</td>\n",
       "      <td>0.001266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>health</td>\n",
       "      <td>54</td>\n",
       "      <td>0.001243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>red</td>\n",
       "      <td>54</td>\n",
       "      <td>0.001243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>interaction</td>\n",
       "      <td>53</td>\n",
       "      <td>0.001220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>psychology</td>\n",
       "      <td>51</td>\n",
       "      <td>0.001174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>folding</td>\n",
       "      <td>51</td>\n",
       "      <td>0.001174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>alignment</td>\n",
       "      <td>51</td>\n",
       "      <td>0.001174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>ecoli</td>\n",
       "      <td>51</td>\n",
       "      <td>0.001174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>parasitology</td>\n",
       "      <td>51</td>\n",
       "      <td>0.001174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>hearing</td>\n",
       "      <td>51</td>\n",
       "      <td>0.001174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>death</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>breathing</td>\n",
       "      <td>50</td>\n",
       "      <td>0.001151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>mrna</td>\n",
       "      <td>49</td>\n",
       "      <td>0.001128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>mitosis</td>\n",
       "      <td>49</td>\n",
       "      <td>0.001128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>systems</td>\n",
       "      <td>49</td>\n",
       "      <td>0.001128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>yeast</td>\n",
       "      <td>48</td>\n",
       "      <td>0.001105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>regulation</td>\n",
       "      <td>48</td>\n",
       "      <td>0.001105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>theory</td>\n",
       "      <td>47</td>\n",
       "      <td>0.001082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>temperature</td>\n",
       "      <td>47</td>\n",
       "      <td>0.001082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>meiosis</td>\n",
       "      <td>47</td>\n",
       "      <td>0.001082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>diet</td>\n",
       "      <td>46</td>\n",
       "      <td>0.001059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>epidemiology</td>\n",
       "      <td>44</td>\n",
       "      <td>0.001013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>software</td>\n",
       "      <td>44</td>\n",
       "      <td>0.001013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Tag_Name  Frequency  Relative_Frequency\n",
       "234         biology       3686            0.084831\n",
       "688           human       2218            0.051046\n",
       "648        genetics       1942            0.044694\n",
       "246       evolution       1302            0.029965\n",
       "586       molecular       1272            0.029274\n",
       "193            cell       1161            0.026720\n",
       "348    biochemistry        984            0.022646\n",
       "282             dna        977            0.022485\n",
       "206      physiology        896            0.020621\n",
       "229  bioinformatics        663            0.015259\n",
       "457    neuroscience        614            0.014131\n",
       "492          botany        565            0.013003\n",
       "704         zoology        545            0.012543\n",
       "334         species        486            0.011185\n",
       "2    identification        462            0.010633\n",
       "232         anatomy        456            0.010495\n",
       "351        proteins        443            0.010195\n",
       "376    microbiology        421            0.009689\n",
       "34             gene        379            0.008722\n",
       "374      entomology        378            0.008699\n",
       "695        homework        372            0.008561\n",
       "675      population        355            0.008170\n",
       "168           plant        337            0.007756\n",
       "428      immunology        331            0.007618\n",
       "35       metabolism        324            0.007457\n",
       "493    bacteriology        312            0.007181\n",
       "556      sequencing        277            0.006375\n",
       "574         ecology        275            0.006329\n",
       "214             rna        271            0.006237\n",
       "55            brain        270            0.006214\n",
       "..              ...        ...                 ...\n",
       "68         plasmids         56            0.001289\n",
       "165        protocol         55            0.001266\n",
       "400          genome         55            0.001266\n",
       "49    bioenergetics         55            0.001266\n",
       "479             snp         55            0.001266\n",
       "350     translation         55            0.001266\n",
       "301     epigenetics         55            0.001266\n",
       "265        kinetics         55            0.001266\n",
       "183          health         54            0.001243\n",
       "127             red         54            0.001243\n",
       "96      interaction         53            0.001220\n",
       "456      psychology         51            0.001174\n",
       "693         folding         51            0.001174\n",
       "674       alignment         51            0.001174\n",
       "239           ecoli         51            0.001174\n",
       "510    parasitology         51            0.001174\n",
       "203         hearing         51            0.001174\n",
       "15            death         50            0.001151\n",
       "697       breathing         50            0.001151\n",
       "667            mrna         49            0.001128\n",
       "441         mitosis         49            0.001128\n",
       "142         systems         49            0.001128\n",
       "120           yeast         48            0.001105\n",
       "235      regulation         48            0.001105\n",
       "636          theory         47            0.001082\n",
       "63      temperature         47            0.001082\n",
       "638         meiosis         47            0.001082\n",
       "407            diet         46            0.001059\n",
       "590    epidemiology         44            0.001013\n",
       "526        software         44            0.001013\n",
       "\n",
       "[165 rows x 3 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tags with relative frequency above 0.001\n",
    "NUMBER_of_Biology_tags_above_limit=len(Biology_tags.loc[Biology_tags['Relative_Frequency']>0.001])\n",
    "Biology_tags.loc[Biology_tags['Relative_Frequency']>0.001]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13196"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUMBER_of_biology_posts=len(df1)\n",
    "NUMBER_of_biology_posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> We will do the same for the other topics as well</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EXPLORE cooking\n",
    "#remove punctuation \n",
    "df2['title'] = df2['title'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "df2['content'] = df2['content'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "df2['tags'] = df2['tags'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "df2['title_content']=df2['title']+df2['content']\n",
    "#create Dataframe with the allready existed tags\n",
    "df2['tags_tokens'] = df2['tags'].str.split()\n",
    "tokens_tags=df2['tags_tokens'].tolist()\n",
    "tokens_tags = np.asarray(tokens_tags)\n",
    "tokens_tags=[j for i in tokens_tags for j in i]\n",
    "number_of_tags=len(tokens_tags) #total number of tags\n",
    "Cooking_tags = FreqDist(tokens_tags)\n",
    "Cooking_tags = pd.DataFrame.from_dict(Cooking_tags, orient='index').reset_index()\n",
    "Cooking_tags.rename(columns = {'index':'Tag_Name', 0:'Frequency'}, inplace=True)\n",
    "#explore tags\n",
    "Cooking_tags=Cooking_tags[['Tag_Name','Frequency']].sort_values(by='Frequency',ascending=False)\n",
    "Cooking_tags['Frequency'].describe()\n",
    "Cooking_tags['Relative_Frequency']=Cooking_tags['Frequency']/Cooking_tags['Frequency'].sum()\n",
    "NUMBER_of_Cooking_tags_above_limit=len(Cooking_tags.loc[Cooking_tags['Relative_Frequency']>0.001])\n",
    "NUMBER_of_Cooking_posts=len(df2)\n",
    "NUMBER_of_different_Cooking_tags=len(Cooking_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EXPLORE crypto\n",
    "#remove punctuation \n",
    "df3['title'] = df3['title'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "df3['content'] = df3['content'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "df3['tags'] = df3['tags'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "df3['title_content']=df3['title']+df3['content']\n",
    "#create Dataframe with the allready existed tags\n",
    "df3['tags_tokens'] = df3['tags'].str.split()\n",
    "tokens_tags=df3['tags_tokens'].tolist()\n",
    "tokens_tags = np.asarray(tokens_tags)\n",
    "tokens_tags=[j for i in tokens_tags for j in i]\n",
    "number_of_tags=len(tokens_tags) #total number of tags\n",
    "Crypto_tags = FreqDist(tokens_tags)\n",
    "Crypto_tags = pd.DataFrame.from_dict(Crypto_tags, orient='index').reset_index()\n",
    "Crypto_tags.rename(columns = {'index':'Tag_Name', 0:'Frequency'}, inplace=True)\n",
    "#explore tags\n",
    "Crypto_tags=Crypto_tags[['Tag_Name','Frequency']].sort_values(by='Frequency',ascending=False)\n",
    "Crypto_tags['Frequency'].describe()\n",
    "Crypto_tags['Relative_Frequency']=Crypto_tags['Frequency']/Crypto_tags['Frequency'].sum()\n",
    "NUMBER_of_Crypto_tags_above_limit=len(Crypto_tags.loc[Crypto_tags['Relative_Frequency']>0.001])\n",
    "NUMBER_of_Crypto_posts=len(df3)\n",
    "NUMBER_of_different_Crypto_tags=len(Crypto_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EXPLORE diy\n",
    "#remove punctuation \n",
    "df4['title'] = df4['title'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "df4['content'] = df4['content'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "df4['tags'] = df4['tags'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "df4['title_content']=df4['title']+df4['content']\n",
    "#create Dataframe with the allready existed tags\n",
    "df4['tags_tokens'] = df4['tags'].str.split()\n",
    "tokens_tags=df4['tags_tokens'].tolist()\n",
    "tokens_tags = np.asarray(tokens_tags)\n",
    "tokens_tags=[j for i in tokens_tags for j in i]\n",
    "number_of_tags=len(tokens_tags) #total number of tags\n",
    "Diy_tags = FreqDist(tokens_tags)\n",
    "Diy_tags = pd.DataFrame.from_dict(Diy_tags, orient='index').reset_index()\n",
    "Diy_tags.rename(columns = {'index':'Tag_Name', 0:'Frequency'}, inplace=True)\n",
    "#explore tags\n",
    "Diy_tags=Diy_tags[['Tag_Name','Frequency']].sort_values(by='Frequency',ascending=False)\n",
    "Diy_tags['Frequency'].describe()\n",
    "Diy_tags['Relative_Frequency']=Diy_tags['Frequency']/Diy_tags['Frequency'].sum()\n",
    "NUMBER_of_Diy_tags_above_limit=len(Diy_tags.loc[Diy_tags['Relative_Frequency']>0.001])\n",
    "NUMBER_of_Diy_posts=len(df4)\n",
    "NUMBER_of_different_Diy_tags=len(Diy_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EXPLORE ROBOTICS\n",
    "#remove punctuation \n",
    "df5['title'] = df5['title'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "df5['content'] = df5['content'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "df5['tags'] = df5['tags'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "df5['title_content']=df5['title']+df5['content']\n",
    "#create Dataframe with the allready existed tags\n",
    "df5['tags_tokens'] = df5['tags'].str.split()\n",
    "tokens_tags=df5['tags_tokens'].tolist()\n",
    "tokens_tags = np.asarray(tokens_tags)\n",
    "tokens_tags=[j for i in tokens_tags for j in i]\n",
    "number_of_tags=len(tokens_tags) #total number of tags\n",
    "Robotics_tags = FreqDist(tokens_tags)\n",
    "Robotics_tags = pd.DataFrame.from_dict(Robotics_tags, orient='index').reset_index()\n",
    "Robotics_tags.rename(columns = {'index':'Tag_Name', 0:'Frequency'}, inplace=True)\n",
    "#explore tags\n",
    "Robotics_tags=Robotics_tags[['Tag_Name','Frequency']].sort_values(by='Frequency',ascending=False)\n",
    "Robotics_tags['Frequency'].describe()\n",
    "Robotics_tags['Relative_Frequency']=Robotics_tags['Frequency']/Robotics_tags['Frequency'].sum()\n",
    "NUMBER_of_Robotics_tags_above_limit=len(Robotics_tags.loc[Robotics_tags['Relative_Frequency']>0.001])\n",
    "NUMBER_of_robotic_posts=len(df5)\n",
    "NUMBER_of_different_robotic_tags=len(Robotics_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EXPLORE Travel\n",
    "#remove punctuation \n",
    "df6['title'] = df6['title'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "df6['content'] = df6['content'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "df6['tags'] = df6['tags'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "df6['title_content']=df6['title']+df6['content']\n",
    "#create Dataframe with the allready existed tags\n",
    "df6['tags_tokens'] = df6['tags'].str.split()\n",
    "tokens_tags=df6['tags_tokens'].tolist()\n",
    "tokens_tags = np.asarray(tokens_tags)\n",
    "tokens_tags=[j for i in tokens_tags for j in i]\n",
    "number_of_tags=len(tokens_tags) #total number of tags\n",
    "Travel_tags = FreqDist(tokens_tags)\n",
    "Travel_tags = pd.DataFrame.from_dict(Travel_tags, orient='index').reset_index()\n",
    "Travel_tags.rename(columns = {'index':'Tag_Name', 0:'Frequency'}, inplace=True)\n",
    "#explore tags\n",
    "Travel_tags=Travel_tags[['Tag_Name','Frequency']].sort_values(by='Frequency',ascending=False)\n",
    "Travel_tags['Relative_Frequency']=Travel_tags['Frequency']/Travel_tags['Frequency'].sum()\n",
    "Travel_tags.loc[Travel_tags['Relative_Frequency']>Travel_tags['Relative_Frequency'].quantile(0.95)]\n",
    "Travel_tags['Frequency'].quantile(0.95)\n",
    "Travel_tags.loc[Travel_tags['Relative_Frequency']>0.001]\n",
    "NUMBER_of_Travel_posts=len(df6)\n",
    "NUMBER_of_different_Travel_tags=len(Travel_tags)\n",
    "NUMBER_of_Travel_tags_above_limit=len(Travel_tags.loc[Travel_tags['Relative_Frequency']>0.001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Now we will find the percentages tag-words that are covered from the important tags with relative frequency above 0.001</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "percentage_biology=Biology_tags['Frequency'][0:NUMBER_of_Biology_tags_above_limit].sum()/Biology_tags['Frequency'].sum()\n",
    "percentage_cooking=Cooking_tags['Frequency'][0:NUMBER_of_Cooking_tags_above_limit].sum()/Cooking_tags['Frequency'].sum()\n",
    "percentage_robotics=Robotics_tags['Frequency'][0:NUMBER_of_Robotics_tags_above_limit].sum()/Robotics_tags['Frequency'].sum()\n",
    "percentage_Crypto=Crypto_tags['Frequency'][0:NUMBER_of_Crypto_tags_above_limit].sum()/Crypto_tags['Frequency'].sum()\n",
    "percentage_Diy=Diy_tags['Frequency'][0:NUMBER_of_Diy_tags_above_limit].sum()/Diy_tags['Frequency'].sum()\n",
    "percentage_travel=Travel_tags['Frequency'][0:NUMBER_of_Travel_tags_above_limit].sum()/Travel_tags['Frequency'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Important_Tags_above_limit</th>\n",
       "      <th>Number_of_Different_tags</th>\n",
       "      <th>Number_posts</th>\n",
       "      <th>Tag_Percentage_Covered_by_Important_Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Biology</th>\n",
       "      <td>165</td>\n",
       "      <td>710</td>\n",
       "      <td>13196</td>\n",
       "      <td>0.838715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cooking</th>\n",
       "      <td>207</td>\n",
       "      <td>748</td>\n",
       "      <td>15404</td>\n",
       "      <td>0.815615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crypto</th>\n",
       "      <td>160</td>\n",
       "      <td>472</td>\n",
       "      <td>10432</td>\n",
       "      <td>0.903378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diy</th>\n",
       "      <td>220</td>\n",
       "      <td>742</td>\n",
       "      <td>25918</td>\n",
       "      <td>0.847878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Robotics</th>\n",
       "      <td>151</td>\n",
       "      <td>266</td>\n",
       "      <td>2771</td>\n",
       "      <td>0.947656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Travel</th>\n",
       "      <td>188</td>\n",
       "      <td>1723</td>\n",
       "      <td>19279</td>\n",
       "      <td>0.750286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Important_Tags_above_limit  Number_of_Different_tags  Number_posts  \\\n",
       "Biology                          165                       710         13196   \n",
       "Cooking                          207                       748         15404   \n",
       "Crypto                           160                       472         10432   \n",
       "Diy                              220                       742         25918   \n",
       "Robotics                         151                       266          2771   \n",
       "Travel                           188                      1723         19279   \n",
       "\n",
       "          Tag_Percentage_Covered_by_Important_Tags  \n",
       "Biology                                   0.838715  \n",
       "Cooking                                   0.815615  \n",
       "Crypto                                    0.903378  \n",
       "Diy                                       0.847878  \n",
       "Robotics                                  0.947656  \n",
       "Travel                                    0.750286  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " d = {'Number_posts' : pd.Series([NUMBER_of_biology_posts, NUMBER_of_Cooking_posts,NUMBER_of_Crypto_posts,NUMBER_of_Diy_posts,NUMBER_of_robotic_posts,NUMBER_of_Travel_posts],index=['Biology', 'Cooking', 'Crypto', 'Diy','Robotics','Travel']),\n",
    "     'Number_of_Different_tags' : pd.Series([NUMBER_of_different_Biology_tags, NUMBER_of_different_Cooking_tags, NUMBER_of_different_Crypto_tags, NUMBER_of_different_Diy_tags,NUMBER_of_different_robotic_tags,NUMBER_of_different_Travel_tags], index=['Biology', 'Cooking', 'Crypto', 'Diy','Robotics','Travel']),\n",
    "     'Important_Tags_above_limit': pd.Series([NUMBER_of_Biology_tags_above_limit, NUMBER_of_Cooking_tags_above_limit, NUMBER_of_Crypto_tags_above_limit, NUMBER_of_Diy_tags_above_limit,NUMBER_of_Robotics_tags_above_limit,NUMBER_of_Travel_tags_above_limit], index=['Biology', 'Cooking', 'Crypto', 'Diy','Robotics','Travel']),\n",
    "    'Tag_Percentage_Covered_by_Important_Tags': pd.Series([percentage_biology, percentage_cooking, percentage_Crypto, percentage_Diy,percentage_robotics,percentage_travel], index=['Biology', 'Cooking', 'Crypto', 'Diy','Robotics','Travel'])}\n",
    "\n",
    "Tag_stat = pd.DataFrame(d)\n",
    "Tag_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87000"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tag_stat['Number_posts'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4661"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tag_stat['Number_of_Different_tags'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8505880965025491"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tag_stat['Tag_Percentage_Covered_by_Important_Tags'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181.83333333333334"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tag_stat['Important_Tags_above_limit'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As we see above the most important tags are covering a 85% of the total token-tag-words, with an average number of 181 per category</p>\n",
    "<p>Let's check now our idea by tring it to robotics</p>\n",
    "<p></p>\n",
    "<p>We will use LDA to robotics</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>what is the right approach to write the spin c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>how can i modify a low cost hobby servo to run...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>what useful gaits exist for a six legged robot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                      title_content\n",
       "0   1  what is the right approach to write the spin c...\n",
       "1   2  how can i modify a low cost hobby servo to run...\n",
       "2   3  what useful gaits exist for a six legged robot..."
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robotics=df5 \n",
    "robotics['title'] = robotics['title'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "robotics['content'] = robotics['content'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "robotics['title_content']=robotics['title']+robotics['content']\n",
    "robotics=robotics[['id','title_content']]\n",
    "robotics.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Now we suppose 10 different subtopics for robotics with 15 top words in each in order to make a bag of important words in robotics </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "motor motors speed torque dc control quadcopter power jpg current esc stepper pwm gear controller\n",
      "Topic #1:\n",
      "0x00 serial data void double acc output return write sensor pin arduino input print gpio\n",
      "Topic #2:\n",
      "robot arduino robotics control project raspberry board sensors usb software working sensor camera build program\n",
      "Topic #3:\n",
      "robot create space obstacle obstacles roomba irobot pdf planning 00 surface path goal files mobile\n",
      "Topic #4:\n",
      "state filter slam map kalman pose function matrix algorithm measurement odometry model robot vector ekf\n",
      "Topic #5:\n",
      "pid error ros controller output loop youtube watch control kp quadcopter gain arm kd package\n",
      "Topic #6:\n",
      "servo arm robot robots robotic servos stereo vision design systems cameras weight cost low torque\n",
      "Topic #7:\n",
      "robot position sensor angle distance velocity pitch data roll yaw imu axis rate sensors path\n",
      "Topic #8:\n",
      "battery batteries wire power air lipo design gps charge charger area pole antenna supply circuit\n",
      "Topic #9:\n",
      "theta float joint matrix axis dot cos position angle kinematics inverse robot rotation current frame\n"
     ]
    }
   ],
   "source": [
    "n_topics = 10\n",
    "n_top_words = 15\n",
    "\n",
    "def top_words(model, feature_names, n_top_words):\n",
    "    tags = []    \n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        tags.append({'Topic': topic_idx, 'Tags': \" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])})        \n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    tags=pd.DataFrame(tags)\n",
    "    return tags\n",
    "    print()\n",
    "    \n",
    "        \n",
    "\n",
    "tf_vectorizer = CountVectorizer(ngram_range=(1, 1), min_df=10,stop_words=stopwords)\n",
    "tf = tf_vectorizer.fit_transform(robotics['title_content'])\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "lda.fit(tf)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "robotic_top=top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tags</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>motor motors speed torque dc control quadcopte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x00 serial data void double acc output return...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>robot arduino robotics control project raspber...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>robot create space obstacle obstacles roomba i...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>state filter slam map kalman pose function mat...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pid error ros controller output loop youtube w...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>servo arm robot robots robotic servos stereo v...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>robot position sensor angle distance velocity ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>battery batteries wire power air lipo design g...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>theta float joint matrix axis dot cos position...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tags  Topic\n",
       "0  motor motors speed torque dc control quadcopte...      0\n",
       "1  0x00 serial data void double acc output return...      1\n",
       "2  robot arduino robotics control project raspber...      2\n",
       "3  robot create space obstacle obstacles roomba i...      3\n",
       "4  state filter slam map kalman pose function mat...      4\n",
       "5  pid error ros controller output loop youtube w...      5\n",
       "6  servo arm robot robots robotic servos stereo v...      6\n",
       "7  robot position sensor angle distance velocity ...      7\n",
       "8  battery batteries wire power air lipo design g...      8\n",
       "9  theta float joint matrix axis dot cos position...      9"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robotic_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#put tags in a list\n",
    "robotic_top['Tags']=robotic_top['Tags'].str.split()\n",
    "robotics_tags=[]\n",
    "for i in range(0,len(robotic_top)):\n",
    "    robotics_tags+=robotic_top['Tags'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keep unique\n",
    "robotics_tags = list(set(robotics_tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see how many tags are unique\n",
    "len(robotics_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> We will search each robotic post (title+content) if it contains the word-tokens predicted from LDA method as most important in robotics subtopics. For memory error reasons we will do it ontly for the first 30 posts</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "robotics['title_content']=robotics['title_content'].str.split()\n",
    "robotics['title_content'] = robotics['title_content'].apply(lambda tokens: [token for token in tokens if token not in stopwords])\n",
    "robotics['tags']=''\n",
    "\n",
    "for i in range(0,30):\n",
    "    for j in robotics_tags:\n",
    "        if j in robotics['title_content'][i]:\n",
    "            robotics['tags'][i]+=\"\".join(str(j)+\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_content</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[approach, write, spin, controller, soccer, ro...</td>\n",
       "      <td>stepper software pwm angle goal write void pid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[modify, low, cost, hobby, servo, freely, hobb...</td>\n",
       "      <td>low software arduino angle state cost power se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[gaits, exist, legged, robot, pros, cons, oric...</td>\n",
       "      <td>robot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[microcontrollers, socs, robotics, project, st...</td>\n",
       "      <td>arduino raspberry project build robotics systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[nearest, neighbor, data, structure, euclidean...</td>\n",
       "      <td>data algorithm arm working space kd serial robot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>[robotics, software, platforms, operating, sys...</td>\n",
       "      <td>software data project design robotics robotic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>[software, design, pcb, robotics, field, softw...</td>\n",
       "      <td>software design robots robotics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18</td>\n",
       "      <td>[methods, tuning, process, noise, kalman, filt...</td>\n",
       "      <td>kalman filter error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19</td>\n",
       "      <td>[keyboard, control, map, scalar, based, moveme...</td>\n",
       "      <td>working controller control map</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>[ideas, shooting, ball, soccer, robot, option,...</td>\n",
       "      <td>robot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23</td>\n",
       "      <td>[oss, optical, object, avoidance, beginning, l...</td>\n",
       "      <td>sensors project power control robot speed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25</td>\n",
       "      <td>[choose, propeller, motor, combination, quadco...</td>\n",
       "      <td>power quadcopter battery motor motors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26</td>\n",
       "      <td>[cheap, web, buy, robotic, pieces, love, progr...</td>\n",
       "      <td>robots servos robotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>37</td>\n",
       "      <td>[mobile, robot, localization, map, localize, m...</td>\n",
       "      <td>mobile robot map</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>39</td>\n",
       "      <td>[gesture, based, input, robot, pros, cons, xti...</td>\n",
       "      <td>power input robot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>42</td>\n",
       "      <td>[tyre, tread, suited, road, robot, expected, d...</td>\n",
       "      <td>build robot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>43</td>\n",
       "      <td>[algorithm, balancing, wheeled, robot, gyrosco...</td>\n",
       "      <td>algorithm input control robot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>44</td>\n",
       "      <td>[choosing, dimensions, underwater, glider, pot...</td>\n",
       "      <td>low error power build</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>46</td>\n",
       "      <td>[effective, type, rechargeable, battery, takin...</td>\n",
       "      <td>project lipo cost weight power build battery c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>48</td>\n",
       "      <td>[protect, sensitive, components, damage, vibra...</td>\n",
       "      <td>robots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>49</td>\n",
       "      <td>[accurate, obtain, locational, fix, gps, gps, ...</td>\n",
       "      <td>low gps robot antenna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>53</td>\n",
       "      <td>[algorithm, constructing, map, explored, area,...</td>\n",
       "      <td>algorithm sensors area gps build robotic robot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>55</td>\n",
       "      <td>[adding, external, heat, sinking, dynamixel, r...</td>\n",
       "      <td>design servo motor robotics servos control tor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>57</td>\n",
       "      <td>[detect, dc, motor, robot, starting, fail, cha...</td>\n",
       "      <td>sensors rotation dc circuit motor robot speed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>60</td>\n",
       "      <td>[stabilize, wheeled, robot, gyroscopes, wheele...</td>\n",
       "      <td>files algorithm jpg position pid controller co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>65</td>\n",
       "      <td>[calculating, efficiency, mecanum, wheels, usf...</td>\n",
       "      <td>robotics robot speed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75</td>\n",
       "      <td>[arduino, control, connection, pins, driver, p...</td>\n",
       "      <td>low stepper arduino data power pin motor contr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>85</td>\n",
       "      <td>[shape, memory, alloy, wire, robot, gripper, a...</td>\n",
       "      <td>batteries sensors arm pwm design weight circui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>88</td>\n",
       "      <td>[mechanical, design, motorized, spherical, cas...</td>\n",
       "      <td>stepper goal axis design servo control surface...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>91</td>\n",
       "      <td>[determines, noise, actuator, produces, youtub...</td>\n",
       "      <td>youtube robots watch robot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                      title_content  \\\n",
       "0    1  [approach, write, spin, controller, soccer, ro...   \n",
       "1    2  [modify, low, cost, hobby, servo, freely, hobb...   \n",
       "2    3  [gaits, exist, legged, robot, pros, cons, oric...   \n",
       "3    4  [microcontrollers, socs, robotics, project, st...   \n",
       "4    5  [nearest, neighbor, data, structure, euclidean...   \n",
       "5    6  [robotics, software, platforms, operating, sys...   \n",
       "6   11  [software, design, pcb, robotics, field, softw...   \n",
       "7   18  [methods, tuning, process, noise, kalman, filt...   \n",
       "8   19  [keyboard, control, map, scalar, based, moveme...   \n",
       "9   20  [ideas, shooting, ball, soccer, robot, option,...   \n",
       "10  23  [oss, optical, object, avoidance, beginning, l...   \n",
       "11  25  [choose, propeller, motor, combination, quadco...   \n",
       "12  26  [cheap, web, buy, robotic, pieces, love, progr...   \n",
       "13  37  [mobile, robot, localization, map, localize, m...   \n",
       "14  39  [gesture, based, input, robot, pros, cons, xti...   \n",
       "15  42  [tyre, tread, suited, road, robot, expected, d...   \n",
       "16  43  [algorithm, balancing, wheeled, robot, gyrosco...   \n",
       "17  44  [choosing, dimensions, underwater, glider, pot...   \n",
       "18  46  [effective, type, rechargeable, battery, takin...   \n",
       "19  48  [protect, sensitive, components, damage, vibra...   \n",
       "20  49  [accurate, obtain, locational, fix, gps, gps, ...   \n",
       "21  53  [algorithm, constructing, map, explored, area,...   \n",
       "22  55  [adding, external, heat, sinking, dynamixel, r...   \n",
       "23  57  [detect, dc, motor, robot, starting, fail, cha...   \n",
       "24  60  [stabilize, wheeled, robot, gyroscopes, wheele...   \n",
       "25  65  [calculating, efficiency, mecanum, wheels, usf...   \n",
       "26  75  [arduino, control, connection, pins, driver, p...   \n",
       "27  85  [shape, memory, alloy, wire, robot, gripper, a...   \n",
       "28  88  [mechanical, design, motorized, spherical, cas...   \n",
       "29  91  [determines, noise, actuator, produces, youtub...   \n",
       "\n",
       "                                                 tags  \n",
       "0   stepper software pwm angle goal write void pid...  \n",
       "1   low software arduino angle state cost power se...  \n",
       "2                                              robot   \n",
       "3   arduino raspberry project build robotics systems   \n",
       "4   data algorithm arm working space kd serial robot   \n",
       "5   software data project design robotics robotic ...  \n",
       "6                    software design robots robotics   \n",
       "7                                kalman filter error   \n",
       "8                     working controller control map   \n",
       "9                                              robot   \n",
       "10         sensors project power control robot speed   \n",
       "11             power quadcopter battery motor motors   \n",
       "12                             robots servos robotic   \n",
       "13                                  mobile robot map   \n",
       "14                                 power input robot   \n",
       "15                                       build robot   \n",
       "16                     algorithm input control robot   \n",
       "17                             low error power build   \n",
       "18  project lipo cost weight power build battery c...  \n",
       "19                                            robots   \n",
       "20                             low gps robot antenna   \n",
       "21  algorithm sensors area gps build robotic robot...  \n",
       "22  design servo motor robotics servos control tor...  \n",
       "23  sensors rotation dc circuit motor robot speed ...  \n",
       "24  files algorithm jpg position pid controller co...  \n",
       "25                              robotics robot speed   \n",
       "26  low stepper arduino data power pin motor contr...  \n",
       "27  batteries sensors arm pwm design weight circui...  \n",
       "28  stepper goal axis design servo control surface...  \n",
       "29                        youtube robots watch robot   "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robotics.head(30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Explore the distances (levenshtein,sorensen and jaccard methods) between tags predicted and the actual tags to see how much difference is there "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.79076853110608591"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import distance\n",
    "\n",
    "robotics['distance']=''\n",
    "for i in range(0,30):\n",
    "    robotics['distance'][i]=distance.nlevenshtein(robotics['tags'][i], df5['tags'][i], method=1)  # shortest alignment\n",
    "robotics['distance'][0:30].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30996311792366771"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robotics['distance2']=''\n",
    "for i in range(0,30):\n",
    "    robotics['distance2'][i]=distance.sorensen(robotics['tags'][i], df5['tags'][i])  # shortest alignment\n",
    "robotics['distance2'][0:30].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.44960393278891736"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robotics['distance3']=''\n",
    "for i in range(0,30):\n",
    "    robotics['distance3'][i]=distance.jaccard(robotics['tags'][i], df5['tags'][i])  # shortest alignment\n",
    "robotics['distance3'][0:30].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> So there is an indication that the actual tags are partly predicted with our method.Sorensen's method shows the closest distance.</p> \n",
    "<p> We will continue by finding  250 important words (Above mean fo the rest of the topics that is 181) with LDA method, assuming there are 10 subtopics in physics with 25 top words each. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "space bar frame theory vector symmetry tensor gauge field string metric group spacetime relativity lorentz transformation reference general action lagrangian dimensions spin invariant fields scalar\n",
      "Topic #1:\n",
      "speed earth universe space gravity matter observer sun gravitational big star orbit distance event dark moving travel planet horizon wikipedia faster object mass objects relative\n",
      "Topic #2:\n",
      "energy water temperature pressure heat air gas kinetic volume fluid liquid potential density thermal constant surface molecules increase entropy equilibrium law process ideal tube rate\n",
      "Topic #3:\n",
      "electron energy photon frequency spin electrons photons atom sound momentum decay scattering wavelength hydrogen spectrum proton amplitude band level neutron nucleus atomic emitted angular radiation\n",
      "Topic #4:\n",
      "physics quantum theory function mechanics physical model wikipedia classical phase equation book point order principle equations functions real mathematical position answer space hamiltonian general simple\n",
      "Topic #5:\n",
      "current jpg flow wire power voltage circuit beam source laser length resistance material metal block parallel flux plate intensity capacitor angle experiment battery area lens\n",
      "Topic #6:\n",
      "field particle particles magnetic wave charge energy waves mass potential electromagnetic vacuum atoms electrons negative matter charges fields positive interaction gravitational box effect magnet slit\n",
      "Topic #7:\n",
      "partial left equation phi delta mathbf theta alpha lambda rho gamma sigma mathrm text cdot begin beta sqrt epsilon dot sum nabla hbar infty cos\n",
      "Topic #8:\n",
      "force velocity mass electric direction point object acceleration hole motion surface body axis forces distance ball moving constant law radius friction sphere center angular momentum\n",
      "Topic #9:\n",
      "rangle state langle dagger states quantum operator matrix operators pdf sum measurement basis otimes paper information entropy probability arxiv ln ground product entanglement left hilbert\n"
     ]
    }
   ],
   "source": [
    "n_topics = 10\n",
    "n_top_words = 25\n",
    "tf_vectorizer = CountVectorizer(ngram_range=(1, 1), min_df=10,stop_words=stopwords)\n",
    "tf = tf_vectorizer.fit_transform(df7['title_content'])\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "lda.fit(tf)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "physic_top=top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tags</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>space bar frame theory vector symmetry tensor ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>speed earth universe space gravity matter obse...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>energy water temperature pressure heat air gas...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>electron energy photon frequency spin electron...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>physics quantum theory function mechanics phys...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>current jpg flow wire power voltage circuit be...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>field particle particles magnetic wave charge ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>partial left equation phi delta mathbf theta a...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>force velocity mass electric direction point o...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rangle state langle dagger states quantum oper...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tags  Topic\n",
       "0  space bar frame theory vector symmetry tensor ...      0\n",
       "1  speed earth universe space gravity matter obse...      1\n",
       "2  energy water temperature pressure heat air gas...      2\n",
       "3  electron energy photon frequency spin electron...      3\n",
       "4  physics quantum theory function mechanics phys...      4\n",
       "5  current jpg flow wire power voltage circuit be...      5\n",
       "6  field particle particles magnetic wave charge ...      6\n",
       "7  partial left equation phi delta mathbf theta a...      7\n",
       "8  force velocity mass electric direction point o...      8\n",
       "9  rangle state langle dagger states quantum oper...      9"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physic_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['material',\n",
       " 'lagrangian',\n",
       " 'lens',\n",
       " 'group',\n",
       " 'ln',\n",
       " 'matrix',\n",
       " 'molecules',\n",
       " 'particle',\n",
       " 'reference',\n",
       " 'positive',\n",
       " 'energy',\n",
       " 'relative',\n",
       " 'model',\n",
       " 'voltage',\n",
       " 'forces',\n",
       " 'wave',\n",
       " 'function',\n",
       " 'photons',\n",
       " 'beta',\n",
       " 'string',\n",
       " 'quantum',\n",
       " 'sun',\n",
       " 'faster',\n",
       " 'volume',\n",
       " 'level',\n",
       " 'constant',\n",
       " 'relativity',\n",
       " 'big',\n",
       " 'object',\n",
       " 'box',\n",
       " 'gravity',\n",
       " 'universe',\n",
       " 'partial',\n",
       " 'objects',\n",
       " 'delta',\n",
       " 'simple',\n",
       " 'radiation',\n",
       " 'point',\n",
       " 'nucleus',\n",
       " 'sqrt',\n",
       " 'potential',\n",
       " 'jpg',\n",
       " 'dark',\n",
       " 'water',\n",
       " 'ball',\n",
       " 'flow',\n",
       " 'cos',\n",
       " 'magnet',\n",
       " 'phase',\n",
       " 'basis',\n",
       " 'text',\n",
       " 'entropy',\n",
       " 'vector',\n",
       " 'kinetic',\n",
       " 'charges',\n",
       " 'sound',\n",
       " 'momentum',\n",
       " 'distance',\n",
       " 'friction',\n",
       " 'theta',\n",
       " 'probability',\n",
       " 'law',\n",
       " 'magnetic',\n",
       " 'gauge',\n",
       " 'horizon',\n",
       " 'rate',\n",
       " 'position',\n",
       " 'metal',\n",
       " 'cdot',\n",
       " 'direction',\n",
       " 'operator',\n",
       " 'angle',\n",
       " 'vacuum',\n",
       " 'length',\n",
       " 'tube',\n",
       " 'hamiltonian',\n",
       " 'resistance',\n",
       " 'intensity',\n",
       " 'photon',\n",
       " 'gas',\n",
       " 'state',\n",
       " 'travel',\n",
       " 'frame',\n",
       " 'scalar',\n",
       " 'answer',\n",
       " 'sigma',\n",
       " 'earth',\n",
       " 'observer',\n",
       " 'moving',\n",
       " 'temperature',\n",
       " 'electromagnetic',\n",
       " 'parallel',\n",
       " 'infty',\n",
       " 'transformation',\n",
       " 'physics',\n",
       " 'operators',\n",
       " 'block',\n",
       " 'air',\n",
       " 'left',\n",
       " 'axis',\n",
       " 'atomic',\n",
       " 'entanglement',\n",
       " 'lambda',\n",
       " 'hbar',\n",
       " 'pressure',\n",
       " 'wavelength',\n",
       " 'ideal',\n",
       " 'frequency',\n",
       " 'decay',\n",
       " 'experiment',\n",
       " 'otimes',\n",
       " 'phi',\n",
       " 'hole',\n",
       " 'area',\n",
       " 'star',\n",
       " 'fluid',\n",
       " 'proton',\n",
       " 'neutron',\n",
       " 'interaction',\n",
       " 'increase',\n",
       " 'electrons',\n",
       " 'symmetry',\n",
       " 'power',\n",
       " 'epsilon',\n",
       " 'principle',\n",
       " 'hydrogen',\n",
       " 'real',\n",
       " 'wikipedia',\n",
       " 'planet',\n",
       " 'mathbf',\n",
       " 'theory',\n",
       " 'order',\n",
       " 'spacetime',\n",
       " 'electron',\n",
       " 'equilibrium',\n",
       " 'thermal',\n",
       " 'dimensions',\n",
       " 'circuit',\n",
       " 'atoms',\n",
       " 'battery',\n",
       " 'classical',\n",
       " 'charge',\n",
       " 'space',\n",
       " 'rho',\n",
       " 'source',\n",
       " 'product',\n",
       " 'flux',\n",
       " 'states',\n",
       " 'langle',\n",
       " 'gravitational',\n",
       " 'equation',\n",
       " 'waves',\n",
       " 'surface',\n",
       " 'mechanics',\n",
       " 'dot',\n",
       " 'invariant',\n",
       " 'orbit',\n",
       " 'tensor',\n",
       " 'gamma',\n",
       " 'paper',\n",
       " 'spin',\n",
       " 'nabla',\n",
       " 'event',\n",
       " 'ground',\n",
       " 'spectrum',\n",
       " 'band',\n",
       " 'plate',\n",
       " 'motion',\n",
       " 'atom',\n",
       " 'rangle',\n",
       " 'velocity',\n",
       " 'mass',\n",
       " 'general',\n",
       " 'density',\n",
       " 'mathrm',\n",
       " 'center',\n",
       " 'alpha',\n",
       " 'lorentz',\n",
       " 'bar',\n",
       " 'effect',\n",
       " 'capacitor',\n",
       " 'wire',\n",
       " 'speed',\n",
       " 'emitted',\n",
       " 'slit',\n",
       " 'field',\n",
       " 'heat',\n",
       " 'sphere',\n",
       " 'laser',\n",
       " 'fields',\n",
       " 'liquid',\n",
       " 'information',\n",
       " 'action',\n",
       " 'arxiv',\n",
       " 'force',\n",
       " 'particles',\n",
       " 'electric',\n",
       " 'acceleration',\n",
       " 'equations',\n",
       " 'process',\n",
       " 'dagger',\n",
       " 'physical',\n",
       " 'scattering',\n",
       " 'sum',\n",
       " 'measurement',\n",
       " 'mathematical',\n",
       " 'current',\n",
       " 'matter',\n",
       " 'metric',\n",
       " 'angular',\n",
       " 'book',\n",
       " 'beam',\n",
       " 'body',\n",
       " 'radius',\n",
       " 'pdf',\n",
       " 'hilbert',\n",
       " 'negative',\n",
       " 'begin',\n",
       " 'functions',\n",
       " 'amplitude']"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physic_top2=physic_top\n",
    "physic_top2['Tags']=physic_top2['Tags'].str.split()\n",
    "physics_tags=[]\n",
    "for i in range(0,len(physic_top2)):\n",
    "    physics_tags+=physic_top2['Tags'][i]\n",
    "physics_tags = list(set(physics_tags)) #keep unique\n",
    "physics_tags #see possible tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(physics_tags)  #see unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df7 = pd.read_csv('test.csv')\n",
    "df7['title_content']=df7['title']+df7['title']\n",
    "df7['tags']=\"\"\n",
    "df7['title_content'] = df7['title_content'].str.lower().str.replace(RE_PUNCTUATION, ' ')\n",
    "df_test=df7[['id','title_content','tags']]\n",
    "df_test['title_content_tokens'] = df_test['title_content'].str.split() #split to strings\n",
    "#remove stopwords\n",
    "df_test['title_content_tokens'] = df_test['title_content_tokens'].apply(lambda tokens: [token for token in tokens if token not in stopwords])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_content</th>\n",
       "      <th>tags</th>\n",
       "      <th>title_content_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>what is spin as it relates to subatomic partic...</td>\n",
       "      <td></td>\n",
       "      <td>[spin, relates, subatomic, particles, spin, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>what is your simplest explanation of the strin...</td>\n",
       "      <td></td>\n",
       "      <td>[simplest, explanation, string, theory, simple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>lie theory  representations and particle physi...</td>\n",
       "      <td></td>\n",
       "      <td>[lie, theory, representations, particle, physi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>will determinism be ever possible will determi...</td>\n",
       "      <td></td>\n",
       "      <td>[determinism, determinism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>hamilton s principlehamilton s principle</td>\n",
       "      <td></td>\n",
       "      <td>[hamilton, principlehamilton, principle]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>what is sound and how is it produced what is s...</td>\n",
       "      <td></td>\n",
       "      <td>[sound, produced, sound, produced]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>what experiment would disprove string theory w...</td>\n",
       "      <td></td>\n",
       "      <td>[experiment, disprove, string, theory, experim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>why does the sky change color  why the sky is ...</td>\n",
       "      <td></td>\n",
       "      <td>[sky, color, sky, blue, sunrise, night, sky, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19</td>\n",
       "      <td>how s the energy of particle collisions calcul...</td>\n",
       "      <td></td>\n",
       "      <td>[energy, particle, collisions, calculated, ene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>monte carlo usemonte carlo use</td>\n",
       "      <td></td>\n",
       "      <td>[monte, carlo, usemonte, carlo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24</td>\n",
       "      <td>does leaning  banking  help cause turning on a...</td>\n",
       "      <td></td>\n",
       "      <td>[leaning, banking, turning, bicycle, leaning, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26</td>\n",
       "      <td>velocity of object from electromagnetic fieldv...</td>\n",
       "      <td></td>\n",
       "      <td>[velocity, object, electromagnetic, fieldveloc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27</td>\n",
       "      <td>what is the difference between a measurement a...</td>\n",
       "      <td></td>\n",
       "      <td>[measurement, interaction, quantum, mechanics,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>29</td>\n",
       "      <td>how to calculate average speed how to calculat...</td>\n",
       "      <td></td>\n",
       "      <td>[calculate, average, speed, calculate, average...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31</td>\n",
       "      <td>lay explanation of the special theory of relat...</td>\n",
       "      <td></td>\n",
       "      <td>[lay, explanation, special, theory, relativity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32</td>\n",
       "      <td>how to show that the coriolis effect is irrele...</td>\n",
       "      <td></td>\n",
       "      <td>[coriolis, effect, irrelevant, whirl, vortex, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>35</td>\n",
       "      <td>where do magnets get the energy to repel where...</td>\n",
       "      <td></td>\n",
       "      <td>[magnets, energy, repel, magnets, energy, repel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>37</td>\n",
       "      <td>how to check einstein like equations on their ...</td>\n",
       "      <td></td>\n",
       "      <td>[check, einstein, equations, correspondence, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>41</td>\n",
       "      <td>impressions of topological field theories in m...</td>\n",
       "      <td></td>\n",
       "      <td>[impressions, topological, field, theories, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49</td>\n",
       "      <td>what is a capacitive screen sensing what is a ...</td>\n",
       "      <td></td>\n",
       "      <td>[capacitive, screen, sensing, capacitive, scre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                      title_content tags  \\\n",
       "0    1  what is spin as it relates to subatomic partic...        \n",
       "1    2  what is your simplest explanation of the strin...        \n",
       "2    3  lie theory  representations and particle physi...        \n",
       "3    7  will determinism be ever possible will determi...        \n",
       "4    9           hamilton s principlehamilton s principle        \n",
       "5   13  what is sound and how is it produced what is s...        \n",
       "6   15  what experiment would disprove string theory w...        \n",
       "7   17  why does the sky change color  why the sky is ...        \n",
       "8   19  how s the energy of particle collisions calcul...        \n",
       "9   21                     monte carlo usemonte carlo use        \n",
       "10  24  does leaning  banking  help cause turning on a...        \n",
       "11  26  velocity of object from electromagnetic fieldv...        \n",
       "12  27  what is the difference between a measurement a...        \n",
       "13  29  how to calculate average speed how to calculat...        \n",
       "14  31  lay explanation of the special theory of relat...        \n",
       "15  32  how to show that the coriolis effect is irrele...        \n",
       "16  35  where do magnets get the energy to repel where...        \n",
       "17  37  how to check einstein like equations on their ...        \n",
       "18  41  impressions of topological field theories in m...        \n",
       "19  49  what is a capacitive screen sensing what is a ...        \n",
       "\n",
       "                                 title_content_tokens  \n",
       "0   [spin, relates, subatomic, particles, spin, re...  \n",
       "1   [simplest, explanation, string, theory, simple...  \n",
       "2   [lie, theory, representations, particle, physi...  \n",
       "3                          [determinism, determinism]  \n",
       "4            [hamilton, principlehamilton, principle]  \n",
       "5                  [sound, produced, sound, produced]  \n",
       "6   [experiment, disprove, string, theory, experim...  \n",
       "7   [sky, color, sky, blue, sunrise, night, sky, c...  \n",
       "8   [energy, particle, collisions, calculated, ene...  \n",
       "9                     [monte, carlo, usemonte, carlo]  \n",
       "10  [leaning, banking, turning, bicycle, leaning, ...  \n",
       "11  [velocity, object, electromagnetic, fieldveloc...  \n",
       "12  [measurement, interaction, quantum, mechanics,...  \n",
       "13  [calculate, average, speed, calculate, average...  \n",
       "14  [lay, explanation, special, theory, relativity...  \n",
       "15  [coriolis, effect, irrelevant, whirl, vortex, ...  \n",
       "16   [magnets, energy, repel, magnets, energy, repel]  \n",
       "17  [check, einstein, equations, correspondence, r...  \n",
       "18  [impressions, topological, field, theories, ma...  \n",
       "19  [capacitive, screen, sensing, capacitive, scre...  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2881: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "#for i in range(0,len(df7)):\n",
    "for i in range(0,200):\n",
    "    for j in physics_tags:\n",
    "        if j in df_test['title_content_tokens'][i]:\n",
    "            df_test['tags'][i]+=\"\".join(str(j)+\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title_content</th>\n",
       "      <th>tags</th>\n",
       "      <th>title_content_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>what is spin as it relates to subatomic partic...</td>\n",
       "      <td>spin particles</td>\n",
       "      <td>[spin, relates, subatomic, particles, spin, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>what is your simplest explanation of the strin...</td>\n",
       "      <td>string theory</td>\n",
       "      <td>[simplest, explanation, string, theory, simple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>lie theory  representations and particle physi...</td>\n",
       "      <td>particle physics theory</td>\n",
       "      <td>[lie, theory, representations, particle, physi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>will determinism be ever possible will determi...</td>\n",
       "      <td></td>\n",
       "      <td>[determinism, determinism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>hamilton s principlehamilton s principle</td>\n",
       "      <td>principle</td>\n",
       "      <td>[hamilton, principlehamilton, principle]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>what is sound and how is it produced what is s...</td>\n",
       "      <td>sound</td>\n",
       "      <td>[sound, produced, sound, produced]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>what experiment would disprove string theory w...</td>\n",
       "      <td>string experiment theory</td>\n",
       "      <td>[experiment, disprove, string, theory, experim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>why does the sky change color  why the sky is ...</td>\n",
       "      <td></td>\n",
       "      <td>[sky, color, sky, blue, sunrise, night, sky, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19</td>\n",
       "      <td>how s the energy of particle collisions calcul...</td>\n",
       "      <td>particle energy</td>\n",
       "      <td>[energy, particle, collisions, calculated, ene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>monte carlo usemonte carlo use</td>\n",
       "      <td></td>\n",
       "      <td>[monte, carlo, usemonte, carlo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24</td>\n",
       "      <td>does leaning  banking  help cause turning on a...</td>\n",
       "      <td></td>\n",
       "      <td>[leaning, banking, turning, bicycle, leaning, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26</td>\n",
       "      <td>velocity of object from electromagnetic fieldv...</td>\n",
       "      <td>object electromagnetic velocity field</td>\n",
       "      <td>[velocity, object, electromagnetic, fieldveloc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27</td>\n",
       "      <td>what is the difference between a measurement a...</td>\n",
       "      <td>quantum interaction mechanics measurement</td>\n",
       "      <td>[measurement, interaction, quantum, mechanics,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>29</td>\n",
       "      <td>how to calculate average speed how to calculat...</td>\n",
       "      <td>speed</td>\n",
       "      <td>[calculate, average, speed, calculate, average...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31</td>\n",
       "      <td>lay explanation of the special theory of relat...</td>\n",
       "      <td>relativity theory</td>\n",
       "      <td>[lay, explanation, special, theory, relativity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32</td>\n",
       "      <td>how to show that the coriolis effect is irrele...</td>\n",
       "      <td>effect</td>\n",
       "      <td>[coriolis, effect, irrelevant, whirl, vortex, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>35</td>\n",
       "      <td>where do magnets get the energy to repel where...</td>\n",
       "      <td>energy</td>\n",
       "      <td>[magnets, energy, repel, magnets, energy, repel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>37</td>\n",
       "      <td>how to check einstein like equations on their ...</td>\n",
       "      <td>real equations</td>\n",
       "      <td>[check, einstein, equations, correspondence, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>41</td>\n",
       "      <td>impressions of topological field theories in m...</td>\n",
       "      <td>field</td>\n",
       "      <td>[impressions, topological, field, theories, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49</td>\n",
       "      <td>what is a capacitive screen sensing what is a ...</td>\n",
       "      <td></td>\n",
       "      <td>[capacitive, screen, sensing, capacitive, scre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>52</td>\n",
       "      <td>how do 2 magnets spin by themselves if positio...</td>\n",
       "      <td>spin</td>\n",
       "      <td>[magnets, spin, positioned, precisely, magnets...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>62</td>\n",
       "      <td>why is the lhc circular and 27km long why is t...</td>\n",
       "      <td></td>\n",
       "      <td>[lhc, circular, 27km, lhc, circular, 27km]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>68</td>\n",
       "      <td>what causes polarised materials to change colo...</td>\n",
       "      <td></td>\n",
       "      <td>[polarised, materials, colour, stress, polaris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>71</td>\n",
       "      <td>what is an intuitive explanation of gouy phase...</td>\n",
       "      <td>phase</td>\n",
       "      <td>[intuitive, explanation, gouy, phase, intuitiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>72</td>\n",
       "      <td>proton therapy in cancer treatmentproton thera...</td>\n",
       "      <td>proton</td>\n",
       "      <td>[proton, therapy, cancer, treatmentproton, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>73</td>\n",
       "      <td>how do physicists use solutions to the yang ba...</td>\n",
       "      <td>equation</td>\n",
       "      <td>[physicists, solutions, yang, baxter, equation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75</td>\n",
       "      <td>mnemonics to remember various properties of ma...</td>\n",
       "      <td></td>\n",
       "      <td>[mnemonics, remember, properties, materialsmne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>78</td>\n",
       "      <td>why do neutrons repel each other why do neutro...</td>\n",
       "      <td></td>\n",
       "      <td>[neutrons, repel, neutrons, repel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>79</td>\n",
       "      <td>is quantum entanglement mediated by an interac...</td>\n",
       "      <td>quantum entanglement interaction</td>\n",
       "      <td>[quantum, entanglement, mediated, interaction,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>83</td>\n",
       "      <td>how is squeezed light produced how is squeezed...</td>\n",
       "      <td></td>\n",
       "      <td>[squeezed, produced, squeezed, produced]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>610</td>\n",
       "      <td>equilibrium and movement of a cylinder with as...</td>\n",
       "      <td>equilibrium mass</td>\n",
       "      <td>[equilibrium, movement, cylinder, asymmetric, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>613</td>\n",
       "      <td>two point correlation function for planar pott...</td>\n",
       "      <td>model function point</td>\n",
       "      <td>[point, correlation, function, planar, potts, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>614</td>\n",
       "      <td>where do atoms go after collision where do ato...</td>\n",
       "      <td>atoms</td>\n",
       "      <td>[atoms, collision, atoms, collision]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>615</td>\n",
       "      <td>is it possible to make glasses that make every...</td>\n",
       "      <td></td>\n",
       "      <td>[glasses, brighter, magnify, focus, glasses, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>619</td>\n",
       "      <td>why is it so hard to accelerate macroscopic ob...</td>\n",
       "      <td>objects</td>\n",
       "      <td>[hard, accelerate, macroscopic, objects, hard,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>622</td>\n",
       "      <td>list of scattering phenomenalist of scattering...</td>\n",
       "      <td>scattering</td>\n",
       "      <td>[list, scattering, phenomenalist, scattering, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>625</td>\n",
       "      <td>is a  third quantization  possible is a  third...</td>\n",
       "      <td></td>\n",
       "      <td>[quantization, quantization]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>629</td>\n",
       "      <td>why does one experience a short pull in the wr...</td>\n",
       "      <td>direction</td>\n",
       "      <td>[experience, short, pull, wrong, direction, ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>630</td>\n",
       "      <td>is it possible to observe interference from 2 ...</td>\n",
       "      <td></td>\n",
       "      <td>[observe, interference, independent, optical, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>634</td>\n",
       "      <td>evolution in the interpretation of the dirac e...</td>\n",
       "      <td>equation</td>\n",
       "      <td>[evolution, interpretation, dirac, equationevo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>639</td>\n",
       "      <td>logarithmic wind speed profilelogarithmic wind...</td>\n",
       "      <td>speed</td>\n",
       "      <td>[logarithmic, wind, speed, profilelogarithmic,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>647</td>\n",
       "      <td>how do molecules vibrate after collision how d...</td>\n",
       "      <td>molecules</td>\n",
       "      <td>[molecules, vibrate, collision, molecules, vib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>650</td>\n",
       "      <td>what is an  idea  in terms of time space and m...</td>\n",
       "      <td>space matter</td>\n",
       "      <td>[idea, terms, space, matter, idea, terms, spac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>651</td>\n",
       "      <td>why isn t the iss electrically charged why isn...</td>\n",
       "      <td></td>\n",
       "      <td>[isn, iss, electrically, isn, iss, electrically]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>661</td>\n",
       "      <td>is it possible to blur an image in such way th...</td>\n",
       "      <td></td>\n",
       "      <td>[blur, person, sight, problems, sharp, blur, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>672</td>\n",
       "      <td>what is the relation of sound propagation to a...</td>\n",
       "      <td>sound air pressure</td>\n",
       "      <td>[relation, sound, propagation, air, pressure, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>676</td>\n",
       "      <td>is it possible to destroy proton in proton pro...</td>\n",
       "      <td>proton</td>\n",
       "      <td>[destroy, proton, proton, proton, collision, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>679</td>\n",
       "      <td>learning physics online learning physics online</td>\n",
       "      <td>physics</td>\n",
       "      <td>[learning, physics, online, learning, physics,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>691</td>\n",
       "      <td>which gets you first when you are falling into...</td>\n",
       "      <td>radiation hole</td>\n",
       "      <td>[falling, hole, hole, singularity, cosmic, bac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>703</td>\n",
       "      <td>is gravity a vector or tensor function and doe...</td>\n",
       "      <td>function gravity vector tensor velocity</td>\n",
       "      <td>[gravity, vector, tensor, function, gravity, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>704</td>\n",
       "      <td>are the physical laws scale dependent are the ...</td>\n",
       "      <td>physical</td>\n",
       "      <td>[physical, laws, scale, dependent, physical, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>716</td>\n",
       "      <td>relativistic speed energy relation  is this co...</td>\n",
       "      <td>energy speed</td>\n",
       "      <td>[relativistic, speed, energy, relation, correc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>721</td>\n",
       "      <td>if the size of universe doubledif the size of ...</td>\n",
       "      <td>universe</td>\n",
       "      <td>[size, universe, doubledif, size, universe, do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>723</td>\n",
       "      <td>help fill in my understanding of the polywell ...</td>\n",
       "      <td></td>\n",
       "      <td>[understanding, polywell, fusion, reactorhelp,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>727</td>\n",
       "      <td>what condition is fulfilled by the path of a m...</td>\n",
       "      <td>mass</td>\n",
       "      <td>[condition, fulfilled, path, mass, sliding, lu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>728</td>\n",
       "      <td>will a ball slide down a lumpy hill over the s...</td>\n",
       "      <td>ball</td>\n",
       "      <td>[ball, slide, lumpy, hill, path, rolls, hill, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>741</td>\n",
       "      <td>electromagnetic field as a connection in a vec...</td>\n",
       "      <td>vector electromagnetic field</td>\n",
       "      <td>[electromagnetic, field, connection, vector, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>743</td>\n",
       "      <td>suggested reading for renormalization  not onl...</td>\n",
       "      <td></td>\n",
       "      <td>[suggested, reading, renormalization, qft, sug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>755</td>\n",
       "      <td>how many atoms per light year does light encou...</td>\n",
       "      <td>atoms space</td>\n",
       "      <td>[atoms, year, encounter, traversing, interstel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>756</td>\n",
       "      <td>mathematics of ads cftmathematics of ads cft</td>\n",
       "      <td></td>\n",
       "      <td>[mathematics, ads, cftmathematics, ads, cft]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                      title_content  \\\n",
       "0      1  what is spin as it relates to subatomic partic...   \n",
       "1      2  what is your simplest explanation of the strin...   \n",
       "2      3  lie theory  representations and particle physi...   \n",
       "3      7  will determinism be ever possible will determi...   \n",
       "4      9           hamilton s principlehamilton s principle   \n",
       "5     13  what is sound and how is it produced what is s...   \n",
       "6     15  what experiment would disprove string theory w...   \n",
       "7     17  why does the sky change color  why the sky is ...   \n",
       "8     19  how s the energy of particle collisions calcul...   \n",
       "9     21                     monte carlo usemonte carlo use   \n",
       "10    24  does leaning  banking  help cause turning on a...   \n",
       "11    26  velocity of object from electromagnetic fieldv...   \n",
       "12    27  what is the difference between a measurement a...   \n",
       "13    29  how to calculate average speed how to calculat...   \n",
       "14    31  lay explanation of the special theory of relat...   \n",
       "15    32  how to show that the coriolis effect is irrele...   \n",
       "16    35  where do magnets get the energy to repel where...   \n",
       "17    37  how to check einstein like equations on their ...   \n",
       "18    41  impressions of topological field theories in m...   \n",
       "19    49  what is a capacitive screen sensing what is a ...   \n",
       "20    52  how do 2 magnets spin by themselves if positio...   \n",
       "21    62  why is the lhc circular and 27km long why is t...   \n",
       "22    68  what causes polarised materials to change colo...   \n",
       "23    71  what is an intuitive explanation of gouy phase...   \n",
       "24    72  proton therapy in cancer treatmentproton thera...   \n",
       "25    73  how do physicists use solutions to the yang ba...   \n",
       "26    75  mnemonics to remember various properties of ma...   \n",
       "27    78  why do neutrons repel each other why do neutro...   \n",
       "28    79  is quantum entanglement mediated by an interac...   \n",
       "29    83  how is squeezed light produced how is squeezed...   \n",
       "..   ...                                                ...   \n",
       "170  610  equilibrium and movement of a cylinder with as...   \n",
       "171  613  two point correlation function for planar pott...   \n",
       "172  614  where do atoms go after collision where do ato...   \n",
       "173  615  is it possible to make glasses that make every...   \n",
       "174  619  why is it so hard to accelerate macroscopic ob...   \n",
       "175  622  list of scattering phenomenalist of scattering...   \n",
       "176  625  is a  third quantization  possible is a  third...   \n",
       "177  629  why does one experience a short pull in the wr...   \n",
       "178  630  is it possible to observe interference from 2 ...   \n",
       "179  634  evolution in the interpretation of the dirac e...   \n",
       "180  639  logarithmic wind speed profilelogarithmic wind...   \n",
       "181  647  how do molecules vibrate after collision how d...   \n",
       "182  650  what is an  idea  in terms of time space and m...   \n",
       "183  651  why isn t the iss electrically charged why isn...   \n",
       "184  661  is it possible to blur an image in such way th...   \n",
       "185  672  what is the relation of sound propagation to a...   \n",
       "186  676  is it possible to destroy proton in proton pro...   \n",
       "187  679   learning physics online learning physics online    \n",
       "188  691  which gets you first when you are falling into...   \n",
       "189  703  is gravity a vector or tensor function and doe...   \n",
       "190  704  are the physical laws scale dependent are the ...   \n",
       "191  716  relativistic speed energy relation  is this co...   \n",
       "192  721  if the size of universe doubledif the size of ...   \n",
       "193  723  help fill in my understanding of the polywell ...   \n",
       "194  727  what condition is fulfilled by the path of a m...   \n",
       "195  728  will a ball slide down a lumpy hill over the s...   \n",
       "196  741  electromagnetic field as a connection in a vec...   \n",
       "197  743  suggested reading for renormalization  not onl...   \n",
       "198  755  how many atoms per light year does light encou...   \n",
       "199  756       mathematics of ads cftmathematics of ads cft   \n",
       "\n",
       "                                           tags  \\\n",
       "0                               spin particles    \n",
       "1                                string theory    \n",
       "2                      particle physics theory    \n",
       "3                                                 \n",
       "4                                    principle    \n",
       "5                                        sound    \n",
       "6                     string experiment theory    \n",
       "7                                                 \n",
       "8                              particle energy    \n",
       "9                                                 \n",
       "10                                                \n",
       "11       object electromagnetic velocity field    \n",
       "12   quantum interaction mechanics measurement    \n",
       "13                                       speed    \n",
       "14                           relativity theory    \n",
       "15                                      effect    \n",
       "16                                      energy    \n",
       "17                              real equations    \n",
       "18                                       field    \n",
       "19                                                \n",
       "20                                        spin    \n",
       "21                                                \n",
       "22                                                \n",
       "23                                       phase    \n",
       "24                                      proton    \n",
       "25                                    equation    \n",
       "26                                                \n",
       "27                                                \n",
       "28            quantum entanglement interaction    \n",
       "29                                                \n",
       "..                                          ...   \n",
       "170                           equilibrium mass    \n",
       "171                       model function point    \n",
       "172                                      atoms    \n",
       "173                                               \n",
       "174                                    objects    \n",
       "175                                 scattering    \n",
       "176                                               \n",
       "177                                  direction    \n",
       "178                                               \n",
       "179                                   equation    \n",
       "180                                      speed    \n",
       "181                                  molecules    \n",
       "182                               space matter    \n",
       "183                                               \n",
       "184                                               \n",
       "185                         sound air pressure    \n",
       "186                                     proton    \n",
       "187                                    physics    \n",
       "188                             radiation hole    \n",
       "189    function gravity vector tensor velocity    \n",
       "190                                   physical    \n",
       "191                               energy speed    \n",
       "192                                   universe    \n",
       "193                                               \n",
       "194                                       mass    \n",
       "195                                       ball    \n",
       "196               vector electromagnetic field    \n",
       "197                                               \n",
       "198                                atoms space    \n",
       "199                                               \n",
       "\n",
       "                                  title_content_tokens  \n",
       "0    [spin, relates, subatomic, particles, spin, re...  \n",
       "1    [simplest, explanation, string, theory, simple...  \n",
       "2    [lie, theory, representations, particle, physi...  \n",
       "3                           [determinism, determinism]  \n",
       "4             [hamilton, principlehamilton, principle]  \n",
       "5                   [sound, produced, sound, produced]  \n",
       "6    [experiment, disprove, string, theory, experim...  \n",
       "7    [sky, color, sky, blue, sunrise, night, sky, c...  \n",
       "8    [energy, particle, collisions, calculated, ene...  \n",
       "9                      [monte, carlo, usemonte, carlo]  \n",
       "10   [leaning, banking, turning, bicycle, leaning, ...  \n",
       "11   [velocity, object, electromagnetic, fieldveloc...  \n",
       "12   [measurement, interaction, quantum, mechanics,...  \n",
       "13   [calculate, average, speed, calculate, average...  \n",
       "14   [lay, explanation, special, theory, relativity...  \n",
       "15   [coriolis, effect, irrelevant, whirl, vortex, ...  \n",
       "16    [magnets, energy, repel, magnets, energy, repel]  \n",
       "17   [check, einstein, equations, correspondence, r...  \n",
       "18   [impressions, topological, field, theories, ma...  \n",
       "19   [capacitive, screen, sensing, capacitive, scre...  \n",
       "20   [magnets, spin, positioned, precisely, magnets...  \n",
       "21          [lhc, circular, 27km, lhc, circular, 27km]  \n",
       "22   [polarised, materials, colour, stress, polaris...  \n",
       "23   [intuitive, explanation, gouy, phase, intuitiv...  \n",
       "24   [proton, therapy, cancer, treatmentproton, the...  \n",
       "25   [physicists, solutions, yang, baxter, equation...  \n",
       "26   [mnemonics, remember, properties, materialsmne...  \n",
       "27                  [neutrons, repel, neutrons, repel]  \n",
       "28   [quantum, entanglement, mediated, interaction,...  \n",
       "29            [squeezed, produced, squeezed, produced]  \n",
       "..                                                 ...  \n",
       "170  [equilibrium, movement, cylinder, asymmetric, ...  \n",
       "171  [point, correlation, function, planar, potts, ...  \n",
       "172               [atoms, collision, atoms, collision]  \n",
       "173  [glasses, brighter, magnify, focus, glasses, b...  \n",
       "174  [hard, accelerate, macroscopic, objects, hard,...  \n",
       "175  [list, scattering, phenomenalist, scattering, ...  \n",
       "176                       [quantization, quantization]  \n",
       "177  [experience, short, pull, wrong, direction, ve...  \n",
       "178  [observe, interference, independent, optical, ...  \n",
       "179  [evolution, interpretation, dirac, equationevo...  \n",
       "180  [logarithmic, wind, speed, profilelogarithmic,...  \n",
       "181  [molecules, vibrate, collision, molecules, vib...  \n",
       "182  [idea, terms, space, matter, idea, terms, spac...  \n",
       "183   [isn, iss, electrically, isn, iss, electrically]  \n",
       "184  [blur, person, sight, problems, sharp, blur, p...  \n",
       "185  [relation, sound, propagation, air, pressure, ...  \n",
       "186  [destroy, proton, proton, proton, collision, d...  \n",
       "187  [learning, physics, online, learning, physics,...  \n",
       "188  [falling, hole, hole, singularity, cosmic, bac...  \n",
       "189  [gravity, vector, tensor, function, gravity, v...  \n",
       "190  [physical, laws, scale, dependent, physical, l...  \n",
       "191  [relativistic, speed, energy, relation, correc...  \n",
       "192  [size, universe, doubledif, size, universe, do...  \n",
       "193  [understanding, polywell, fusion, reactorhelp,...  \n",
       "194  [condition, fulfilled, path, mass, sliding, lu...  \n",
       "195  [ball, slide, lumpy, hill, path, rolls, hill, ...  \n",
       "196  [electromagnetic, field, connection, vector, b...  \n",
       "197  [suggested, reading, renormalization, qft, sug...  \n",
       "198  [atoms, year, encounter, traversing, interstel...  \n",
       "199       [mathematics, ads, cftmathematics, ads, cft]  \n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>spin particles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>string theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>particle physics theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>principle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13</td>\n",
       "      <td>sound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>string experiment theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19</td>\n",
       "      <td>particle energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26</td>\n",
       "      <td>object electromagnetic velocity field</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27</td>\n",
       "      <td>quantum interaction mechanics measurement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>29</td>\n",
       "      <td>speed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31</td>\n",
       "      <td>relativity theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32</td>\n",
       "      <td>effect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>35</td>\n",
       "      <td>energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>37</td>\n",
       "      <td>real equations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>41</td>\n",
       "      <td>field</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>49</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>52</td>\n",
       "      <td>spin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>62</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>68</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>71</td>\n",
       "      <td>phase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>72</td>\n",
       "      <td>proton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>73</td>\n",
       "      <td>equation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>78</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>79</td>\n",
       "      <td>quantum entanglement interaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>83</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>610</td>\n",
       "      <td>equilibrium mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>613</td>\n",
       "      <td>model function point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>614</td>\n",
       "      <td>atoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>615</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>619</td>\n",
       "      <td>objects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>622</td>\n",
       "      <td>scattering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>625</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>629</td>\n",
       "      <td>direction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>630</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>634</td>\n",
       "      <td>equation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>639</td>\n",
       "      <td>speed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>647</td>\n",
       "      <td>molecules</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>650</td>\n",
       "      <td>space matter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>651</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>661</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>672</td>\n",
       "      <td>sound air pressure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>676</td>\n",
       "      <td>proton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>679</td>\n",
       "      <td>physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>691</td>\n",
       "      <td>radiation hole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>703</td>\n",
       "      <td>function gravity vector tensor velocity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>704</td>\n",
       "      <td>physical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>716</td>\n",
       "      <td>energy speed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>721</td>\n",
       "      <td>universe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>723</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>727</td>\n",
       "      <td>mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>728</td>\n",
       "      <td>ball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>741</td>\n",
       "      <td>vector electromagnetic field</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>743</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>755</td>\n",
       "      <td>atoms space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>756</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        tags\n",
       "0      1                             spin particles \n",
       "1      2                              string theory \n",
       "2      3                    particle physics theory \n",
       "3      7                                            \n",
       "4      9                                  principle \n",
       "5     13                                      sound \n",
       "6     15                   string experiment theory \n",
       "7     17                                            \n",
       "8     19                            particle energy \n",
       "9     21                                            \n",
       "10    24                                            \n",
       "11    26      object electromagnetic velocity field \n",
       "12    27  quantum interaction mechanics measurement \n",
       "13    29                                      speed \n",
       "14    31                          relativity theory \n",
       "15    32                                     effect \n",
       "16    35                                     energy \n",
       "17    37                             real equations \n",
       "18    41                                      field \n",
       "19    49                                            \n",
       "20    52                                       spin \n",
       "21    62                                            \n",
       "22    68                                            \n",
       "23    71                                      phase \n",
       "24    72                                     proton \n",
       "25    73                                   equation \n",
       "26    75                                            \n",
       "27    78                                            \n",
       "28    79           quantum entanglement interaction \n",
       "29    83                                            \n",
       "..   ...                                         ...\n",
       "170  610                           equilibrium mass \n",
       "171  613                       model function point \n",
       "172  614                                      atoms \n",
       "173  615                                            \n",
       "174  619                                    objects \n",
       "175  622                                 scattering \n",
       "176  625                                            \n",
       "177  629                                  direction \n",
       "178  630                                            \n",
       "179  634                                   equation \n",
       "180  639                                      speed \n",
       "181  647                                  molecules \n",
       "182  650                               space matter \n",
       "183  651                                            \n",
       "184  661                                            \n",
       "185  672                         sound air pressure \n",
       "186  676                                     proton \n",
       "187  679                                    physics \n",
       "188  691                             radiation hole \n",
       "189  703    function gravity vector tensor velocity \n",
       "190  704                                   physical \n",
       "191  716                               energy speed \n",
       "192  721                                   universe \n",
       "193  723                                            \n",
       "194  727                                       mass \n",
       "195  728                                       ball \n",
       "196  741               vector electromagnetic field \n",
       "197  743                                            \n",
       "198  755                                atoms space \n",
       "199  756                                            \n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['id','tags']].head(200)\n",
    "#tocsv2=df_test[['id','tags']]\n",
    "#tocsv2.to_csv('example2.csv', sep=',', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
